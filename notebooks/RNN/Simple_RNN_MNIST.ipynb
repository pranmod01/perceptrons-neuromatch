{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Imports\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Scikit-Learn for machine learning utilities\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import manifold\n",
        "\n",
        "# --- Plotting tools\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Torch tools for the RNN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "4-_FIKBwz5zH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. RNN Model Definition {display-mode: \"form\"}\n",
        "class MemoryRNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=100, num_classes=10, rnn_type=\"RNN\"):\n",
        "        super().__init__()\n",
        "        if rnn_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        elif rnn_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(input_dim, hidden_dim, batch_first=True)\n",
        "        else:\n",
        "            self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
        "    def forward(self, x, return_seq=True):\n",
        "        h_seq, _ = self.rnn(x)\n",
        "        dropout = self.dropout(h_seq[:, -1])\n",
        "        out = self.fc(dropout)\n",
        "        if return_seq:\n",
        "            return out, h_seq\n",
        "        return out"
      ],
      "metadata": {
        "id": "01fHG33cfCG0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MemoryDataset(Dataset):\n",
        "    def __init__(self, X, y, noise=None, noise_std=0.05):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.noise = noise\n",
        "        self.noise_std = noise_std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx]\n",
        "        y = self.y[idx]\n",
        "\n",
        "        if self.noise == \"input\":\n",
        "            x = x + self.noise_std * torch.randn_like(x)\n",
        "\n",
        "        return x, y"
      ],
      "metadata": {
        "id": "94hxjsLpfLVH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Training Function (clean / input‑noise / weight‑noise) {display-mode: \"form\"}\n",
        "\n",
        "def train_rnn(X, y, batch_size, variant, learning_rate, epochs=1000, noise_std=0.05):\n",
        "    ds = MemoryDataset(X, y, noise=\"input\" if variant==\"input_noise\" else None,\n",
        "                       noise_std=noise_std)\n",
        "    dl = DataLoader(ds, batch_size, shuffle=True, drop_last=False)\n",
        "    print(len(dl))\n",
        "    print(X.shape[1])\n",
        "\n",
        "    model = MemoryRNN(X.shape[-1], rnn_type='GRU').to(device)\n",
        "    opt   = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    lossf = nn.CrossEntropyLoss()\n",
        "    print(f\" Training variant: {variant}\")\n",
        "\n",
        "    losses = [] # List to store loss at each epoch\n",
        "    for ep in range(epochs):\n",
        "        running = 0\n",
        "        for xb, yb in dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "            # forward\n",
        "            pred, _ = model(xb)\n",
        "            #yb_class_idx = torch.argmax(yb, dim=0).to(torch.float32)\n",
        "            loss = lossf(pred, yb)\n",
        "\n",
        "            # weight noise variant\n",
        "            if variant == \"weight_noise\":\n",
        "                for p in model.parameters():\n",
        "                    p.data += noise_std * torch.randn_like(p)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            opt.step()\n",
        "            running += loss.item()\n",
        "        epoch_loss = running / len(dl)\n",
        "        losses.append(epoch_loss) # Store the loss\n",
        "        print(f\"  Epoch {ep+1}/{epochs} | loss={epoch_loss:.4f}\")\n",
        "    return model, losses # Return model and losses"
      ],
      "metadata": {
        "id": "Rb_X6OsBfRDh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Model Evaluation\n",
        "\n",
        "def evaluate_model(model, X_test, y_test, batch_size=128):\n",
        "    model.eval() # Set model to evaluation mode\n",
        "    test_ds = MemoryDataset(X_test, y_test)\n",
        "    test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    hidden_states_list = []\n",
        "    with torch.no_grad(): # Disable gradient calculations during evaluation\n",
        "        for xb, yb in test_dl:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            outputs, hidden_states = model(xb)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += yb.size(0)\n",
        "            correct += (predicted == yb).sum().item()\n",
        "            hidden_states_list.append(hidden_states)\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'\\nAccuracy on test set: {accuracy:.2f}%')\n",
        "    return accuracy, hidden_states_list"
      ],
      "metadata": {
        "id": "qqingfhn_6VJ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title MNIST Dataset preparation\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(), # Converts PIL Image to FloatTensor and scales to [0, 1]\n",
        "    transforms.Normalize((0.1307,), (0.3081,)) # Standard normalization for MNIST\n",
        "])\n",
        "\n",
        "# Load MNIST training dataset\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=mnist_transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "# Load MNIST test dataset\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    transform=mnist_transform,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "# Prepare data for RNN: reshape images\n",
        "# Each image (1, 28, 28) needs to become (28, 28) for the RNN,\n",
        "# where 28 is sequence_length and 28 is input_dim.\n",
        "# The DataLoader will add the batch dimension, making it (batch_size, 28, 28).\n",
        "\n",
        "# Extract X and y from datasets and reshape\n",
        "# X_train_mnist will be (num_samples, sequence_length, input_dim) -> (60000, 28, 28)\n",
        "X_train_mnist = train_dataset.data.float().view(-1, 28, 28) # Reshape to (num_samples, 28, 28)\n",
        "y_train_mnist = train_dataset.targets # Labels are already LongTensor (integers)\n",
        "\n",
        "# X_test_mnist will be (num_samples, sequence_length, input_dim) -> (10000, 28, 28)\n",
        "X_test_mnist = test_dataset.data.float().view(-1, 28, 28)\n",
        "y_test_mnist = test_dataset.targets"
      ],
      "metadata": {
        "id": "fGxI0DINZggA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9e1f7e-3cd4-4fbc-cb9b-503632fcf1b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 51.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.64MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 11.5MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.39MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_clean, losses = train_rnn(X_train_mnist, y_train_mnist, batch_size=128, learning_rate=1e-3, epochs=20, variant=\"clean\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weUaxy3YxipV",
        "outputId": "8d4927da-ab35-486d-8d36-d8472e856e3c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469\n",
            "28\n",
            " Training variant: clean\n",
            "  Epoch 1/20 | loss=1.0256\n",
            "  Epoch 2/20 | loss=0.5538\n",
            "  Epoch 3/20 | loss=0.4567\n",
            "  Epoch 4/20 | loss=0.3997\n",
            "  Epoch 5/20 | loss=0.3533\n",
            "  Epoch 6/20 | loss=0.3265\n",
            "  Epoch 7/20 | loss=0.3040\n",
            "  Epoch 8/20 | loss=0.2819\n",
            "  Epoch 9/20 | loss=0.2692\n",
            "  Epoch 10/20 | loss=0.2613\n",
            "  Epoch 11/20 | loss=0.2503\n",
            "  Epoch 12/20 | loss=0.2397\n",
            "  Epoch 13/20 | loss=0.2325\n",
            "  Epoch 14/20 | loss=0.2266\n",
            "  Epoch 15/20 | loss=0.2189\n",
            "  Epoch 16/20 | loss=0.2141\n",
            "  Epoch 17/20 | loss=0.2083\n",
            "  Epoch 18/20 | loss=0.2035\n",
            "  Epoch 19/20 | loss=0.2037\n",
            "  Epoch 20/20 | loss=0.1958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluation\n",
        "_, hidden_states = evaluate_model(model_clean, X_test_mnist, y_test_mnist, batch_size=128)\n",
        "# --- Svaes the model hidden states for the test process\n",
        "# --- Dimensions are batch_size=128, image_columns=28, rnn_hidden_units=100\n",
        "torch.save(hidden_states, 'hidden_states.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB1rSlm7_fDa",
        "outputId": "29038702-a513-4ff3-a1a1-08fed5f43678"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy on test set: 92.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_states[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVU30IXiYTBn",
        "outputId": "875b086f-d2ef-4eb8-8a91-1d9eede1a577"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 28, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}