{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "v20zwXDNb-8H",
        "p7gfJR9-iIsw",
        "BNJMXRCiH2Ep"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pe85TzhLQztl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba19063-d12b-4746-d7ae-daba3b261124"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/Neuromatch_project/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9IlQisF1tjh",
        "outputId": "15c375af-773f-41ee-c163-ed05f1f473a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Neuromatch_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f_CREs1KPqmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db7b85b-6e25-4986-9b1e-fa37eecd71f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.7.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "üì± Using device: cuda\n",
            "‚úÖ Setup complete!\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision matplotlib seaborn tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üì± Using device: {device}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "plt.style.use('default')\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "# CNN Feature Extractor (frozen)\n",
        "class CNNFeatureExtractor(nn.Module):\n",
        "    def __init__(self, pretrained_cnn_path, feature_dim=512):\n",
        "        super(CNNFeatureExtractor, self).__init__()\n",
        "        self.cnn = SimpleCNN()\n",
        "        self.cnn.load_state_dict(torch.load(pretrained_cnn_path, map_location=device))\n",
        "        for param in self.cnn.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.cnn.eval()\n",
        "        self.feature_dim = feature_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            features = self.cnn.extract_features(x)\n",
        "        return features\n",
        "\n",
        "# Visual Memory Model\n",
        "class VisualMemoryModel(nn.Module):\n",
        "    def __init__(self, pretrained_cnn_path, rnn_hidden_dim=256,\n",
        "                 projection_dim=128, rnn_type='LSTM', num_layers=2, dropout=0.3):\n",
        "        super(VisualMemoryModel, self).__init__()\n",
        "\n",
        "        self.cnn_features = CNNFeatureExtractor(pretrained_cnn_path)\n",
        "        cnn_feature_dim = self.cnn_features.feature_dim\n",
        "\n",
        "        self.feature_projection = nn.Sequential(\n",
        "            nn.Linear(cnn_feature_dim, projection_dim * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(projection_dim * 2, projection_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout * 0.5)\n",
        "        )\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        if rnn_type == 'LSTM':\n",
        "            self.rnn = nn.LSTM(\n",
        "                projection_dim, rnn_hidden_dim,\n",
        "                num_layers=num_layers,\n",
        "                batch_first=True,\n",
        "                dropout=dropout if num_layers > 1 else 0\n",
        "            )\n",
        "        elif rnn_type == 'GRU':\n",
        "            self.rnn = nn.GRU(\n",
        "                projection_dim, rnn_hidden_dim,\n",
        "                num_layers=num_layers,\n",
        "                batch_first=True,\n",
        "                dropout=dropout if num_layers > 1 else 0\n",
        "            )\n",
        "\n",
        "        self.memory_classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_hidden_dim, rnn_hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_hidden_dim // 2, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout * 0.5),\n",
        "            nn.Linear(64, 2)\n",
        "        )\n",
        "\n",
        "        self.rnn_hidden_dim = rnn_hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.projection_dim = projection_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len = x.size(0), x.size(1)\n",
        "        x = x.view(batch_size * seq_len, *x.shape[2:])\n",
        "        cnn_features = self.cnn_features(x)\n",
        "        projected_features = self.feature_projection(cnn_features)\n",
        "        projected_features = projected_features.view(batch_size, seq_len, -1)\n",
        "\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            rnn_output, (hidden, cell) = self.rnn(projected_features)\n",
        "        else:\n",
        "            rnn_output, hidden = self.rnn(projected_features)\n",
        "\n",
        "        final_output = rnn_output[:, -1, :]\n",
        "        logits = self.memory_classifier(final_output)\n",
        "        return logits\n",
        "\n",
        "    def get_hidden_states(self, x):\n",
        "        batch_size, seq_len = x.size(0), x.size(1)\n",
        "        x = x.view(batch_size * seq_len, *x.shape[2:])\n",
        "        cnn_features = self.cnn_features(x)\n",
        "        projected_features = self.feature_projection(cnn_features)\n",
        "        projected_features = projected_features.view(batch_size, seq_len, -1)\n",
        "\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            rnn_output, _ = self.rnn(projected_features)\n",
        "        else:\n",
        "            rnn_output, _ = self.rnn(projected_features)\n",
        "\n",
        "        return rnn_output, projected_features\n",
        "\n",
        "print(\"‚úÖ Model architecture loaded!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Idu9Y9EG66dx",
        "outputId": "70f4e80b-a70c-49b8-f3ad-14d5c6f772ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model architecture loaded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PRETRAINED_CNN_PATH = 'small_cnn_model.pth'\n",
        "VISUAL_MEMORY_MODEL_PATH = './RNN_model/visual_memory_GRU_noise2.pth' # change this\n",
        "\n",
        "try:\n",
        "    # Create model instance\n",
        "    model = VisualMemoryModel(\n",
        "        pretrained_cnn_path=PRETRAINED_CNN_PATH,\n",
        "        rnn_hidden_dim=256,\n",
        "        projection_dim=128,\n",
        "        rnn_type='GRU',\n",
        "        num_layers=2,\n",
        "        dropout=0.3\n",
        "    ).to(device)\n",
        "\n",
        "    model.load_state_dict(torch.load(VISUAL_MEMORY_MODEL_PATH, map_location=device))\n",
        "    model.eval()\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"‚ùå Error loading model: {e}\")\n",
        "    print(\"üìù Make sure these files exist:\")\n",
        "    print(f\"   - {PRETRAINED_CNN_PATH}\")\n",
        "    print(f\"   - {VISUAL_MEMORY_MODEL_PATH}\")\n",
        "    print(\"\\nüí° Tip: Update the file paths in the cell above to match your files\")"
      ],
      "metadata": {
        "id": "a3Rc-pev7Be6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TEST_DATASET_PATH = './my_datasets/test_1000samples_2dist_20250725_0016.pkl'  # Update this!\n",
        "\n",
        "import glob\n",
        "test_files = glob.glob(TEST_DATASET_PATH)\n",
        "\n",
        "if test_files:\n",
        "    test_path = test_files[0]  # Use the first matching file\n",
        "    print(f\"üìÅ Loading test dataset from: {test_path}\")\n",
        "\n",
        "    with open(test_path, 'rb') as f:\n",
        "        test_data = pickle.load(f)\n",
        "\n",
        "    # Create simple dataset class\n",
        "    class SimpleTestDataset:\n",
        "        def __init__(self, data_dict):\n",
        "            if isinstance(data_dict, dict):\n",
        "                self.samples = data_dict['samples']\n",
        "                self.labels = data_dict['labels']\n",
        "                self.metadata = data_dict['metadata']\n",
        "                self.num_distractors = data_dict.get('num_distractors', 3)\n",
        "            else:\n",
        "                # If it's the dataset object itself\n",
        "                self.samples = data_dict.samples\n",
        "                self.labels = data_dict.labels\n",
        "                self.metadata = data_dict.metadata\n",
        "                self.num_distractors = data_dict.num_distractors\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.samples)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            return self.samples[idx], self.labels[idx]\n",
        "\n",
        "        def get_sample_with_metadata(self, idx):\n",
        "            return self.samples[idx], self.labels[idx], self.metadata[idx]\n",
        "\n",
        "    test_dataset = SimpleTestDataset(test_data)\n",
        "    print(f\"‚úÖ Test dataset loaded: {len(test_dataset)} samples\")\n",
        "\n",
        "else:\n",
        "    raise FileNotFoundError(\"No test dataset found\")\n",
        "\n",
        "\n",
        "# Create DataLoader\n",
        "if 'test_dataset' in locals() and test_dataset is not None:\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    print(f\"üìä Test DataLoader created: {len(test_loader)} batches\")\n",
        "else:\n",
        "    print(\"‚ùå Test dataset not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0ASwl6y8DB8",
        "outputId": "00b8b944-3138-4513-f806-98b2378d1681"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Loading test dataset from: ./my_datasets/test_1000samples_2dist_20250725_0016.pkl\n",
            "‚úÖ Test dataset loaded: 1000 samples\n",
            "üìä Test DataLoader created: 32 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'test_dataset' in locals() and test_dataset is not None:\n",
        "\n",
        "    def test_model_accuracy(model, test_loader, device):\n",
        "        \"\"\"Test overall model accuracy\"\"\"\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        match_correct = 0\n",
        "        match_total = 0\n",
        "        nomatch_correct = 0\n",
        "        nomatch_total = 0\n",
        "\n",
        "        all_predictions = []\n",
        "        all_targets = []\n",
        "        all_confidences = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for sequences, targets in tqdm(test_loader, desc=\"Testing\"):\n",
        "                sequences, targets = sequences.to(device), targets.to(device)\n",
        "                outputs = model(sequences)\n",
        "                probabilities = F.softmax(outputs, dim=1)\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "                # Store predictions and confidences\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_targets.extend(targets.cpu().numpy())\n",
        "                all_confidences.extend(probabilities.max(1)[0].cpu().numpy())\n",
        "\n",
        "                # Separate accuracy for match vs no-match\n",
        "                match_mask = (targets == 1)\n",
        "                nomatch_mask = (targets == 0)\n",
        "\n",
        "                if match_mask.sum() > 0:\n",
        "                    match_correct += predicted[match_mask].eq(targets[match_mask]).sum().item()\n",
        "                    match_total += match_mask.sum().item()\n",
        "\n",
        "                if nomatch_mask.sum() > 0:\n",
        "                    nomatch_correct += predicted[nomatch_mask].eq(targets[nomatch_mask]).sum().item()\n",
        "                    nomatch_total += nomatch_mask.sum().item()\n",
        "\n",
        "        overall_acc = 100. * correct / total\n",
        "        match_acc = 100. * match_correct / max(match_total, 1)\n",
        "        nomatch_acc = 100. * nomatch_correct / max(nomatch_total, 1)\n",
        "        avg_confidence = np.mean(all_confidences)\n",
        "\n",
        "        return {\n",
        "            'overall_accuracy': overall_acc,\n",
        "            'match_accuracy': match_acc,\n",
        "            'nomatch_accuracy': nomatch_acc,\n",
        "            'total_samples': total,\n",
        "            'match_samples': match_total,\n",
        "            'nomatch_samples': nomatch_total,\n",
        "            'average_confidence': avg_confidence,\n",
        "            'predictions': all_predictions,\n",
        "            'targets': all_targets,\n",
        "            'confidences': all_confidences\n",
        "        }\n",
        "\n",
        "    # Run test\n",
        "    results = test_model_accuracy(model, test_loader, device)\n",
        "\n",
        "    print(f\"\\nüìä TEST RESULTS:\")\n",
        "    print(f\"=\" * 40)\n",
        "    print(f\"Overall Accuracy: {results['overall_accuracy']:.2f}%\")\n",
        "    print(f\"Match Trials Accuracy: {results['match_accuracy']:.2f}% ({results['match_samples']} samples)\")\n",
        "    print(f\"No-Match Trials Accuracy: {results['nomatch_accuracy']:.2f}% ({results['nomatch_samples']} samples)\")\n",
        "    print(f\"Average Confidence: {results['average_confidence']:.3f}\")\n",
        "    print(f\"Total Samples: {results['total_samples']}\")\n",
        "\n",
        "    # Performance interpretation\n",
        "    print(f\"\\nüí° PERFORMANCE INTERPRETATION:\")\n",
        "    if results['overall_accuracy'] > 90:\n",
        "        print(\"üéâ Excellent performance!\")\n",
        "    elif results['overall_accuracy'] > 80:\n",
        "        print(\"‚úÖ Good performance!\")\n",
        "    elif results['overall_accuracy'] > 70:\n",
        "        print(\"üìà Decent performance\")\n",
        "    elif results['overall_accuracy'] > 50:\n",
        "        print(\"‚ö†Ô∏è Poor performance\")\n",
        "    else:\n",
        "        print(\"‚ùå Very poor performance - worse than random!\")\n",
        "\n",
        "    print(f\"üéØ Random baseline: 50%\")\n",
        "    print(f\"üìä Your model: {results['overall_accuracy']:.1f}%\")\n",
        "    print(f\"üìà Improvement: +{results['overall_accuracy'] - 50:.1f} percentage points\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå Cannot run tests without test dataset\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYw31wO38h8r",
        "outputId": "fb3a1e32-62b3-46dd-a11c-e13c6ad31e0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:00<00:00, 33.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä TEST RESULTS:\n",
            "========================================\n",
            "Overall Accuracy: 94.10%\n",
            "Match Trials Accuracy: 98.40% (500 samples)\n",
            "No-Match Trials Accuracy: 89.80% (500 samples)\n",
            "Average Confidence: 0.960\n",
            "Total Samples: 1000\n",
            "\n",
            "üí° PERFORMANCE INTERPRETATION:\n",
            "üéâ Excellent performance!\n",
            "üéØ Random baseline: 50%\n",
            "üìä Your model: 94.1%\n",
            "üìà Improvement: +44.1 percentage points\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "dataset = test_dataset\n",
        "\n",
        "indices = np.random.choice(len(dataset), 10, replace=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, idx in enumerate(indices):\n",
        "        sequence, true_label = dataset[idx]\n",
        "        sequence_batch = sequence.unsqueeze(0).to(device)\n",
        "        hidden_states, projected_features = model.get_hidden_states(sequence_batch)\n"
      ],
      "metadata": {
        "id": "hR2LR1O0k3mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_states[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22TA73PAlUGu",
        "outputId": "2ae7c207-38b8-47db-cdc9-c699c5264f00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}