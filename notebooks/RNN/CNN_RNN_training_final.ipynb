{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["v20zwXDNb-8H","p7gfJR9-iIsw","BNJMXRCiH2Ep"],"authorship_tag":"ABX9TyPHez19sT/GwjYTFEKyNg7E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"pe85TzhLQztl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd drive/MyDrive/Neuromatch_project/"],"metadata":{"id":"Z9IlQisF1tjh"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f_CREs1KPqmI"},"outputs":[],"source":["!pip install torch torchvision matplotlib\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import torchvision\n","from torchvision import datasets, transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tqdm import tqdm\n","import random\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","source":["## data generate function"],"metadata":{"id":"Mp4mgiWJ_oCX"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import torch\n","import numpy as np\n","from collections import Counter\n","\n","def visualize_memory_samples(dataset, num_samples=5, figsize=(16, 3)):\n","    \"\"\"\n","    Visualize memory task samples with detailed annotations\n","\n","    Args:\n","        dataset: Your visual memory dataset\n","        num_samples: Number of samples to visualize\n","        figsize: Figure size per sample\n","    \"\"\"\n","\n","    fig, axes = plt.subplots(num_samples, 6, figsize=(figsize[0], figsize[1] * num_samples))\n","    if num_samples == 1:\n","        axes = axes.reshape(1, -1)\n","\n","    fig.suptitle('Visual Memory Task Samples', fontsize=16, y=0.98)\n","\n","    for i in range(num_samples):\n","        # Get sample with metadata\n","        sequence, label, metadata = dataset.get_sample_with_metadata(i)\n","        seq_len = sequence.shape[0]\n","\n","        target_digit = metadata['target_digit']\n","        probe_digit = metadata['probe_digit']\n","        is_match = metadata['is_match']\n","\n","        print(f\"\\nüìã Sample {i+1}:\")\n","        print(f\"  üéØ Target digit: {target_digit}\")\n","        print(f\"  üîç Probe digit: {probe_digit}\")\n","        print(f\"  ‚úÖ Result: {'MATCH' if is_match else 'NO MATCH'}\")\n","        print(f\"  üè∑Ô∏è Label: {label}\")\n","        print(f\"  üìè Sequence length: {seq_len}\")\n","\n","        # Display sequence\n","        for j in range(min(seq_len, 6)):  # Show up to 6 images\n","            ax = axes[i, j]\n","\n","            # Handle different tensor formats\n","            img = sequence[j]\n","            if len(img.shape) == 3:\n","                img = img.squeeze()\n","            img = img.numpy()\n","\n","            ax.imshow(img, cmap='gray', vmin=0, vmax=1)\n","            ax.axis('off')\n","\n","            if j == 0:\n","                # Target image\n","                ax.set_title(f'TARGET\\n(digit: {target_digit})',\n","                           fontweight='bold', color='blue', fontsize=10)\n","                ax.add_patch(plt.Rectangle((0, 0), img.shape[1]-1, img.shape[0]-1,\n","                                         fill=False, edgecolor='blue', linewidth=2))\n","            elif j == seq_len - 1:\n","                # Probe image\n","                match_text = 'MATCH' if is_match else 'NO MATCH'\n","                color = 'green' if is_match else 'red'\n","                ax.set_title(f'PROBE\\n(digit: {probe_digit})\\n{match_text}',\n","                           fontweight='bold', color=color, fontsize=9)\n","                ax.add_patch(plt.Rectangle((0, 0), img.shape[1]-1, img.shape[0]-1,\n","                                         fill=False, edgecolor=color, linewidth=2))\n","            else:\n","                # Distractor/noise image\n","                ax.set_title(f'NOISE {j}', color='gray', fontsize=9)\n","\n","        # Hide unused subplots\n","        for j in range(seq_len, 6):\n","            axes[i, j].axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"EPW_pOsvtFNH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import random\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","from collections import Counter, defaultdict\n","import matplotlib.pyplot as plt\n","\n","class OptimizedNoiseGenerator:\n","    \"\"\"Optimized noise generator with batch processing capabilities\"\"\"\n","\n","    def __init__(self):\n","        # Pre-compute some values for efficiency\n","        self.patch_sizes = [2, 3, 4]\n","\n","    def gaussian_noise(self, shape, noise_level=0.5):\n","        \"\"\"Generate Gaussian noise image - vectorized\"\"\"\n","        noise = torch.randn(shape) * noise_level\n","        return torch.clamp(noise, 0, 1)\n","\n","    def salt_pepper_noise(self, shape, noise_density=0.3):\n","        \"\"\"Generate salt and pepper noise - optimized\"\"\"\n","        noise = torch.rand(shape)\n","        result = torch.rand(shape) * 0.5 + 0.25  # Base gray level\n","\n","        # Vectorized salt and pepper assignment\n","        salt_mask = noise < noise_density/2\n","        pepper_mask = noise > 1 - noise_density/2\n","\n","        result[salt_mask] = 1.0\n","        result[pepper_mask] = 0.0\n","\n","        return result\n","\n","    def random_patches(self, shape, num_patches=10, patch_size=5):\n","        \"\"\"Generate random square patches - optimized\"\"\"\n","        noise = torch.rand(shape) * 0.3 + 0.35\n","        h, w = shape[-2:]\n","\n","        # Pre-compute valid positions\n","        max_x = max(0, w - patch_size)\n","        max_y = max(0, h - patch_size)\n","\n","        if max_x > 0 and max_y > 0:\n","            for _ in range(num_patches):\n","                x = random.randint(0, max_x)\n","                y = random.randint(0, max_y)\n","                intensity = random.random()\n","                noise[..., y:y+patch_size, x:x+patch_size] = intensity\n","\n","        return noise\n","\n","    def scrambled_mnist_batch(self, images, scramble_intensity=0.8):\n","        \"\"\"Create scrambled versions from a batch of images\"\"\"\n","        results = []\n","        for image in images:\n","            if random.random() > scramble_intensity:\n","                results.append(image)\n","                continue\n","\n","            img_np = image.squeeze().numpy()\n","            h, w = img_np.shape\n","\n","            block_size = random.choice(self.patch_sizes)\n","            for i in range(0, h - block_size, block_size):\n","                for j in range(0, w - block_size, block_size):\n","                    block = img_np[i:i+block_size, j:j+block_size].flatten()\n","                    np.random.shuffle(block)\n","                    img_np[i:i+block_size, j:j+block_size] = block.reshape(block_size, block_size)\n","\n","            results.append(torch.tensor(img_np).unsqueeze(0).float())\n","\n","        return results\n","\n","\n","class OptimizedVisualMemoryDataset(Dataset):\n","    \"\"\"Heavily optimized version of Visual Memory Dataset\"\"\"\n","\n","    def __init__(self, mnist_dataset, num_samples=1000, num_distractors=3,\n","                 noise_types=['gaussian', 'salt_pepper', 'patches', 'scrambled'],\n","                 match_probability=0.5, batch_size=100):\n","\n","        self.mnist_dataset = mnist_dataset\n","        self.num_samples = num_samples\n","        self.num_distractors = num_distractors\n","        self.noise_types = noise_types\n","        self.match_probability = match_probability\n","        self.noise_generator = OptimizedNoiseGenerator()\n","\n","        print(f\"üöÄ Generating {num_samples} optimized visual memory samples...\")\n","\n","        # Step 1: Pre-index MNIST data by digit for faster access\n","        print(\"üìã Pre-indexing MNIST data by digit...\")\n","        self._preindex_mnist_data()\n","\n","        # Step 2: Pre-sample all required indices\n","        print(\"üéØ Pre-sampling required indices...\")\n","        self._presample_indices()\n","\n","        # Step 3: Batch generate samples\n","        print(\"‚ö° Batch generating samples...\")\n","        self.samples = []\n","        self.labels = []\n","        self.metadata = []\n","\n","        self._batch_generate_samples(batch_size)\n","\n","        # Print statistics\n","        self._print_statistics()\n","\n","    def _preindex_mnist_data(self):\n","        \"\"\"Pre-index MNIST data by digit for O(1) access\"\"\"\n","        self.digit_indices = defaultdict(list)\n","\n","        # Build index once\n","        for idx, (_, digit) in enumerate(self.mnist_dataset):\n","            self.digit_indices[digit].append(idx)\n","\n","        # Convert to lists for faster random access\n","        for digit in self.digit_indices:\n","            self.digit_indices[digit] = list(self.digit_indices[digit])\n","\n","        print(f\"   Indexed {len(self.digit_indices)} digit classes\")\n","        for digit, indices in self.digit_indices.items():\n","            print(f\"   Digit {digit}: {len(indices)} samples\")\n","\n","    def _presample_indices(self):\n","        \"\"\"Pre-sample all indices needed for the entire dataset\"\"\"\n","        # Determine matches vs non-matches\n","        num_matches = int(self.num_samples * self.match_probability)\n","        self.match_labels = [1] * num_matches + [0] * (self.num_samples - num_matches)\n","        random.shuffle(self.match_labels)\n","\n","        # Pre-sample target indices\n","        all_indices = list(range(len(self.mnist_dataset)))\n","        self.target_indices = random.choices(all_indices, k=self.num_samples)\n","\n","        # Pre-sample probe indices based on match/no-match\n","        self.probe_indices = []\n","        for i, is_match in enumerate(self.match_labels):\n","            target_idx = self.target_indices[i]\n","            _, target_digit = self.mnist_dataset[target_idx]\n","\n","            if is_match:\n","                # Find same digit, different image\n","                same_digit_candidates = [idx for idx in self.digit_indices[target_digit]\n","                                       if idx != target_idx]\n","                if same_digit_candidates:\n","                    probe_idx = random.choice(same_digit_candidates)\n","                else:\n","                    probe_idx = target_idx  # Fallback to same image\n","            else:\n","                # Find different digit\n","                different_digits = [d for d in self.digit_indices.keys() if d != target_digit]\n","                if different_digits:\n","                    different_digit = random.choice(different_digits)\n","                    probe_idx = random.choice(self.digit_indices[different_digit])\n","                else:\n","                    # Fallback - find any different image\n","                    probe_idx = random.choice([idx for idx in all_indices if idx != target_idx])\n","\n","            self.probe_indices.append(probe_idx)\n","\n","    def _batch_generate_samples(self, batch_size):\n","        \"\"\"Generate samples in batches for efficiency\"\"\"\n","\n","        for batch_start in tqdm(range(0, self.num_samples, batch_size),\n","                               desc=\"Generating batches\"):\n","            batch_end = min(batch_start + batch_size, self.num_samples)\n","            batch_samples, batch_labels, batch_metadata = self._create_batch(\n","                batch_start, batch_end)\n","\n","            self.samples.extend(batch_samples)\n","            self.labels.extend(batch_labels)\n","            self.metadata.extend(batch_metadata)\n","\n","    def _create_batch(self, start_idx, end_idx):\n","        \"\"\"Create a batch of samples efficiently\"\"\"\n","        batch_samples = []\n","        batch_labels = []\n","        batch_metadata = []\n","\n","        # Pre-load all needed MNIST images for this batch\n","        target_indices_batch = self.target_indices[start_idx:end_idx]\n","        probe_indices_batch = self.probe_indices[start_idx:end_idx]\n","\n","        # Load target images\n","        target_images = []\n","        target_digits = []\n","        for idx in target_indices_batch:\n","            img, digit = self.mnist_dataset[idx]\n","            target_images.append(img)\n","            target_digits.append(digit)\n","\n","        # Load probe images\n","        probe_images = []\n","        probe_digits = []\n","        for idx in probe_indices_batch:\n","            img, digit = self.mnist_dataset[idx]\n","            probe_images.append(img)\n","            probe_digits.append(digit)\n","\n","        # Generate noise images in batch\n","        batch_size = end_idx - start_idx\n","        noise_images_batch = self._generate_noise_batch(\n","            target_images[0].shape, batch_size * self.num_distractors)\n","\n","        # Assemble sequences\n","        for i in range(batch_size):\n","            # Get images for this sample\n","            target_img = target_images[i]\n","            probe_img = probe_images[i]\n","\n","            # Get noise images for this sample\n","            noise_start = i * self.num_distractors\n","            noise_end = noise_start + self.num_distractors\n","            noise_imgs = noise_images_batch[noise_start:noise_end]\n","\n","            # Create sequence: [target] + [noise images] + [probe]\n","            sequence = [target_img] + noise_imgs + [probe_img]\n","            sequence_tensor = torch.stack(sequence)\n","\n","            # Create metadata\n","            global_idx = start_idx + i\n","            metadata = {\n","                'target_digit': target_digits[i],\n","                'probe_digit': probe_digits[i],\n","                'is_match': bool(self.match_labels[global_idx]),\n","                'target_idx': target_indices_batch[i],\n","                'probe_idx': probe_indices_batch[i],\n","                'sequence_length': len(sequence)\n","            }\n","\n","            batch_samples.append(sequence_tensor)\n","            batch_labels.append(self.match_labels[global_idx])\n","            batch_metadata.append(metadata)\n","\n","        return batch_samples, batch_labels, batch_metadata\n","\n","    def _generate_noise_batch(self, shape, total_noise_images):\n","        \"\"\"Generate a batch of noise images efficiently\"\"\"\n","        noise_images = []\n","\n","        # Group by noise type for batch processing\n","        noise_counts = {noise_type: 0 for noise_type in self.noise_types}\n","        noise_assignments = []\n","\n","        for _ in range(total_noise_images):\n","            noise_type = random.choice(self.noise_types)\n","            noise_assignments.append(noise_type)\n","            noise_counts[noise_type] += 1\n","\n","        # Generate each type in batch\n","        noise_by_type = {}\n","        for noise_type, count in noise_counts.items():\n","            if count > 0:\n","                if noise_type == 'scrambled':\n","                    # For scrambled, we need actual MNIST images\n","                    random_indices = random.choices(range(len(self.mnist_dataset)), k=count)\n","                    random_images = [self.mnist_dataset[idx][0] for idx in random_indices]\n","                    noise_by_type[noise_type] = self.noise_generator.scrambled_mnist_batch(\n","                        random_images)\n","                else:\n","                    # Generate other noise types in batch\n","                    batch_shape = (count,) + shape\n","                    if noise_type == 'gaussian':\n","                        batch_noise = self.noise_generator.gaussian_noise(batch_shape, 0.6)\n","                    elif noise_type == 'salt_pepper':\n","                        batch_noise = self.noise_generator.salt_pepper_noise(batch_shape, 0.4)\n","                    elif noise_type == 'patches':\n","                        batch_noise = torch.stack([\n","                            self.noise_generator.random_patches(shape, 15, 4)\n","                            for _ in range(count)\n","                        ])\n","\n","                    noise_by_type[noise_type] = [batch_noise[i] for i in range(count)]\n","\n","        # Reconstruct in original order\n","        type_counters = {noise_type: 0 for noise_type in self.noise_types}\n","        for noise_type in noise_assignments:\n","            noise_images.append(noise_by_type[noise_type][type_counters[noise_type]])\n","            type_counters[noise_type] += 1\n","\n","        return noise_images\n","\n","    def _print_statistics(self):\n","        \"\"\"Print dataset statistics\"\"\"\n","        match_count = sum(self.labels)\n","        print(f\"\\n‚úÖ Dataset created:\")\n","        print(f\"  Total samples: {self.num_samples}\")\n","        print(f\"  Match trials: {match_count} ({match_count/self.num_samples*100:.1f}%)\")\n","        print(f\"  No-match trials: {self.num_samples-match_count} ({(self.num_samples-match_count)/self.num_samples*100:.1f}%)\")\n","        print(f\"  Sequence length: {self.num_distractors + 2} (1 target + {self.num_distractors} distractors + 1 probe)\")\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        return self.samples[idx], self.labels[idx]\n","\n","    def get_sample_with_metadata(self, idx):\n","        return self.samples[idx], self.labels[idx], self.metadata[idx]\n","\n","    def get_statistics(self):\n","        \"\"\"Get detailed dataset statistics\"\"\"\n","        match_count = sum(self.labels)\n","        total = len(self.labels)\n","\n","        target_digits = [meta['target_digit'] for meta in self.metadata]\n","        probe_digits = [meta['probe_digit'] for meta in self.metadata]\n","\n","        target_counter = Counter(target_digits)\n","        probe_counter = Counter(probe_digits)\n","\n","        return {\n","            'total_samples': total,\n","            'match_trials': match_count,\n","            'nomatch_trials': total - match_count,\n","            'match_percentage': match_count / total * 100,\n","            'target_digit_distribution': dict(target_counter),\n","            'probe_digit_distribution': dict(probe_counter),\n","            'sequence_length': self.num_distractors + 2\n","        }\n","\n","\n","def create_optimized_datasets_for_training(train_size=3000, test_size=1000,\n","                                         num_distractors=3, batch_size=100):\n","    \"\"\"Create optimized datasets for training - much faster\"\"\"\n","\n","    print(\"=\"*60)\n","    print(\"CREATING OPTIMIZED TRAINING DATASETS\")\n","    print(\"=\"*60)\n","\n","    # Import here to avoid issues if not available\n","    from torchvision import datasets, transforms\n","\n","    # Define transform\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.1307,), (0.3081,))\n","    ])\n","\n","    # Load MNIST datasets\n","    print(\"üìÅ Loading MNIST datasets...\")\n","    mnist_train = datasets.MNIST('./data', train=True, download=True, transform=transform)\n","    mnist_test = datasets.MNIST('./data', train=False, download=True, transform=transform)\n","\n","    # Training dataset\n","    print(\"\\nüöÇ Creating optimized training dataset...\")\n","    train_memory_dataset = OptimizedVisualMemoryDataset(\n","        mnist_train,\n","        num_samples=train_size,\n","        num_distractors=num_distractors,\n","        noise_types=['gaussian', 'salt_pepper', 'patches', 'scrambled'],\n","        match_probability=0.5,\n","        batch_size=batch_size\n","    )\n","\n","    # Testing dataset\n","    test_memory_dataset = OptimizedVisualMemoryDataset(\n","        mnist_test,\n","        num_samples=test_size,\n","        num_distractors=num_distractors,\n","        noise_types=['gaussian', 'salt_pepper', 'patches', 'scrambled'],\n","        match_probability=0.5,\n","        batch_size=batch_size\n","    )\n","\n","    # Create DataLoaders\n","    train_loader = DataLoader(train_memory_dataset, batch_size=32, shuffle=True)\n","    test_loader = DataLoader(test_memory_dataset, batch_size=32, shuffle=False)\n","\n","\n","    return train_memory_dataset, test_memory_dataset, train_loader, test_loader\n","\n","\n","# Compatibility function with original interface\n","def create_datasets_for_training(train_size=3000, test_size=1000, num_distractors=3):\n","    \"\"\"Drop-in replacement for original function with massive speedup\"\"\"\n","    return create_optimized_datasets_for_training(\n","        train_size=train_size,\n","        test_size=test_size,\n","        num_distractors=num_distractors,\n","        batch_size=min(100, train_size // 10)  # Adaptive batch size\n","    )\n","\n"],"metadata":{"id":"mQh1AvpfNCv-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## data generate"],"metadata":{"id":"D7h-Pv2r6gK-"}},{"cell_type":"code","source":["train_dataset, test_dataset, train_loader, test_loader = create_datasets_for_training(\n","    train_size=5000,\n","    test_size=1000,\n","    num_distractors=2\n",")\n"],"metadata":{"id":"EIUpuh_qstFB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## save dataset function"],"metadata":{"id":"O2Jl7Fg42oyb"}},{"cell_type":"code","source":["# Save and Load Existing Visual Memory Datasets\n","import torch\n","import pickle\n","import os\n","from datetime import datetime\n","\n","# =============================================================================\n","# OPTION 1: SIMPLE SAVE/LOAD (RECOMMENDED)\n","# =============================================================================\n","\n","def save_datasets_simple(train_dataset, test_dataset, save_dir='./my_datasets/'):\n","    \"\"\"Simple way to save your existing datasets\"\"\"\n","\n","    # Create directory if it doesn't exist\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    # Create descriptive filenames\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","    train_size = len(train_dataset)\n","    test_size = len(test_dataset)\n","    num_distractors = train_dataset.num_distractors\n","\n","    train_filename = f'train_{train_size}samples_{num_distractors}dist_{timestamp}.pkl'\n","    test_filename = f'test_{test_size}samples_{num_distractors}dist_{timestamp}.pkl'\n","\n","    train_path = os.path.join(save_dir, train_filename)\n","    test_path = os.path.join(save_dir, test_filename)\n","\n","    print(f\"Saving datasets to {save_dir}\")\n","    print(f\"Training dataset: {train_filename}\")\n","    print(f\"Test dataset: {test_filename}\")\n","\n","    # Save training dataset\n","    print(\"Saving training dataset...\")\n","    with open(train_path, 'wb') as f:\n","        pickle.dump({\n","            'samples': train_dataset.samples,\n","            'labels': train_dataset.labels,\n","            'metadata': train_dataset.metadata,\n","            'num_samples': train_dataset.num_samples,\n","            'num_distractors': train_dataset.num_distractors,\n","            'noise_types': train_dataset.noise_types,\n","            'match_probability': train_dataset.match_probability,\n","            'creation_time': datetime.now().isoformat(),\n","            'dataset_type': 'training'\n","        }, f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    # Save test dataset\n","    print(\"Saving test dataset...\")\n","    with open(test_path, 'wb') as f:\n","        pickle.dump({\n","            'samples': test_dataset.samples,\n","            'labels': test_dataset.labels,\n","            'metadata': test_dataset.metadata,\n","            'num_samples': test_dataset.num_samples,\n","            'num_distractors': test_dataset.num_distractors,\n","            'noise_types': test_dataset.noise_types,\n","            'match_probability': test_dataset.match_probability,\n","            'creation_time': datetime.now().isoformat(),\n","            'dataset_type': 'testing'\n","        }, f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    # Print file sizes\n","    train_size_mb = os.path.getsize(train_path) / (1024 * 1024)\n","    test_size_mb = os.path.getsize(test_path) / (1024 * 1024)\n","\n","    print(f\"‚úÖ Datasets saved successfully!\")\n","    print(f\"Training dataset: {train_size_mb:.1f} MB\")\n","    print(f\"Test dataset: {test_size_mb:.1f} MB\")\n","    print(f\"Total size: {train_size_mb + test_size_mb:.1f} MB\")\n","\n","    return train_path, test_path\n","\n","def load_datasets_simple(train_path, test_path):\n","    \"\"\"Simple way to load your saved datasets\"\"\"\n","\n","    print(f\"Loading datasets...\")\n","    print(f\"Training: {train_path}\")\n","    print(f\"Test: {test_path}\")\n","\n","    # Check if files exist\n","    if not os.path.exists(train_path):\n","        raise FileNotFoundError(f\"Training dataset not found: {train_path}\")\n","    if not os.path.exists(test_path):\n","        raise FileNotFoundError(f\"Test dataset not found: {test_path}\")\n","\n","    # Load training dataset\n","    print(\"Loading training dataset...\")\n","    with open(train_path, 'rb') as f:\n","        train_data = pickle.load(f)\n","\n","    # Load test dataset\n","    print(\"Loading test dataset...\")\n","    with open(test_path, 'rb') as f:\n","        test_data = pickle.load(f)\n","\n","    # Create dataset objects\n","    train_dataset = SimpleVisualMemoryDataset(train_data)\n","    test_dataset = SimpleVisualMemoryDataset(test_data)\n","\n","    # Print info\n","    print(f\"‚úÖ Datasets loaded successfully!\")\n","    print(f\"Training: {len(train_dataset)} samples\")\n","    print(f\"Test: {len(test_dataset)} samples\")\n","    print(f\"Distractors: {train_dataset.num_distractors}\")\n","    print(f\"Creation time: {train_data.get('creation_time', 'Unknown')}\")\n","\n","    return train_dataset, test_dataset\n","\n","class SimpleVisualMemoryDataset:\n","    \"\"\"Simple dataset class for loaded data\"\"\"\n","    def __init__(self, data_dict):\n","        self.samples = data_dict['samples']\n","        self.labels = data_dict['labels']\n","        self.metadata = data_dict['metadata']\n","        self.num_samples = data_dict['num_samples']\n","        self.num_distractors = data_dict['num_distractors']\n","        self.noise_types = data_dict['noise_types']\n","        self.match_probability = data_dict['match_probability']\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        return self.samples[idx], self.labels[idx]\n","\n","    def get_sample_with_metadata(self, idx):\n","        return self.samples[idx], self.labels[idx], self.metadata[idx]\n","\n","# =============================================================================\n","# OPTION 2: USING DATASET'S BUILT-IN SAVE METHOD\n","# =============================================================================\n","\n","def save_datasets_builtin(train_dataset, test_dataset, save_dir='./my_datasets/'):\n","    \"\"\"Use the dataset's built-in save method (if available)\"\"\"\n","\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    # Generate filenames\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","    train_size = len(train_dataset)\n","    test_size = len(test_dataset)\n","    num_distractors = train_dataset.num_distractors\n","\n","    train_path = os.path.join(save_dir, f'train_{train_size}_{num_distractors}dist_{timestamp}.pkl')\n","    test_path = os.path.join(save_dir, f'test_{test_size}_{num_distractors}dist_{timestamp}.pkl')\n","\n","    # Use built-in save method if your dataset has it\n","    if hasattr(train_dataset, 'save_dataset'):\n","        print(\"Using built-in save method...\")\n","        train_dataset.save_dataset(train_path)\n","        test_dataset.save_dataset(test_path)\n","    else:\n","        print(\"No built-in save method, using simple save...\")\n","        return save_datasets_simple(train_dataset, test_dataset, save_dir)\n","\n","    return train_path, test_path\n","\n","# =============================================================================\n","# CONVENIENCE FUNCTIONS\n","# =============================================================================\n","\n","def quick_save(train_dataset, test_dataset, name=\"my_experiment\"):\n","    \"\"\"Quick save with a custom name\"\"\"\n","\n","    save_dir = f'./saved_datasets/{name}/'\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","    train_path = os.path.join(save_dir, f'train_{timestamp}.pkl')\n","    test_path = os.path.join(save_dir, f'test_{timestamp}.pkl')\n","\n","    # Save datasets\n","    with open(train_path, 'wb') as f:\n","        pickle.dump(train_dataset, f)\n","\n","    with open(test_path, 'wb') as f:\n","        pickle.dump(test_dataset, f)\n","\n","    print(f\"‚úÖ Quick save completed!\")\n","    print(f\"Saved to: {save_dir}\")\n","    print(f\"Training: train_{timestamp}.pkl\")\n","    print(f\"Test: test_{timestamp}.pkl\")\n","\n","    return train_path, test_path\n","\n","def quick_load(train_path, test_path):\n","    \"\"\"Quick load datasets\"\"\"\n","\n","    with open(train_path, 'rb') as f:\n","        train_dataset = pickle.load(f)\n","\n","    with open(test_path, 'rb') as f:\n","        test_dataset = pickle.load(f)\n","\n","    print(f\"‚úÖ Quick load completed!\")\n","    print(f\"Training: {len(train_dataset)} samples\")\n","    print(f\"Test: {len(test_dataset)} samples\")\n","\n","    return train_dataset, test_dataset\n","\n","def list_saved_datasets(save_dir='./my_datasets/'):\n","    \"\"\"List all saved datasets in directory\"\"\"\n","\n","    if not os.path.exists(save_dir):\n","        print(f\"Directory {save_dir} doesn't exist\")\n","        return []\n","\n","    pkl_files = [f for f in os.listdir(save_dir) if f.endswith('.pkl')]\n","\n","    if not pkl_files:\n","        print(f\"No .pkl files found in {save_dir}\")\n","        return []\n","\n","    print(f\"Saved datasets in {save_dir}:\")\n","    print(\"=\" * 50)\n","\n","    datasets = []\n","    for file in sorted(pkl_files):\n","        file_path = os.path.join(save_dir, file)\n","        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n","        mod_time = os.path.getmtime(file_path)\n","        mod_date = datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M:%S')\n","\n","        print(f\"üìÅ {file}\")\n","        print(f\"   Size: {file_size_mb:.1f} MB\")\n","        print(f\"   Modified: {mod_date}\")\n","\n","        datasets.append({\n","            'filename': file,\n","            'path': file_path,\n","            'size_mb': file_size_mb,\n","            'modified': mod_date\n","        })\n","        print()\n","\n","    return datasets\n","\n","# =============================================================================\n","# CREATE DATALOADERS FROM LOADED DATASETS\n","# =============================================================================\n","\n","def create_dataloaders_from_datasets(train_dataset, test_dataset, batch_size=32):\n","    \"\"\"Create DataLoaders from your loaded datasets\"\"\"\n","\n","    from torch.utils.data import DataLoader\n","\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        drop_last=True  # For consistent batch sizes\n","    )\n","\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        drop_last=False\n","    )\n","\n","    print(f\"‚úÖ DataLoaders created!\")\n","    print(f\"Training: {len(train_loader)} batches of size {batch_size}\")\n","    print(f\"Test: {len(test_loader)} batches of size {batch_size}\")\n","\n","    return train_loader, test_loader\n","\n","# =============================================================================\n","# COMPLETE WORKFLOW EXAMPLES\n","# =============================================================================\n","\n","def example_save_workflow():\n","    \"\"\"Example: Save your existing datasets\"\"\"\n","\n","    print(\"=\"*60)\n","    print(\"EXAMPLE: SAVE WORKFLOW\")\n","    print(\"=\"*60)\n","\n","    # Assuming you already have your datasets:\n","    # train_dataset, test_dataset, train_loader, test_loader = create_datasets_for_training(...)\n","\n","    print(\"# Step 1: Save your datasets\")\n","    print(\"train_path, test_path = save_datasets_simple(train_dataset, test_dataset, './my_datasets/')\")\n","    print()\n","    print(\"# OR quick save:\")\n","    print(\"train_path, test_path = quick_save(train_dataset, test_dataset, 'experiment_1')\")\n","\n","def example_load_workflow():\n","    \"\"\"Example: Load and use saved datasets\"\"\"\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"EXAMPLE: LOAD WORKFLOW\")\n","    print(\"=\"*60)\n","\n","    print(\"# Step 1: List available datasets\")\n","    print(\"list_saved_datasets('./my_datasets/')\")\n","    print()\n","    print(\"# Step 2: Load specific datasets\")\n","    print(\"train_dataset, test_dataset = load_datasets_simple(\")\n","    print(\"    './my_datasets/train_1000samples_3dist_20241223_1430.pkl',\")\n","    print(\"    './my_datasets/test_300samples_3dist_20241223_1430.pkl'\")\n","    print(\")\")\n","    print()\n","    print(\"# Step 3: Create DataLoaders\")\n","    print(\"train_loader, test_loader = create_dataloaders_from_datasets(\")\n","    print(\"    train_dataset, test_dataset, batch_size=32\")\n","    print(\")\")\n","    print()\n","    print(\"# Step 4: Start training!\")\n","    print(\"# Now you can use train_loader and test_loader for training\")\n","\n","# =============================================================================\n","# READY-TO-USE EXAMPLE\n","# =============================================================================\n","\n","if __name__ == \"__main__\":\n","    print(\"DATASET SAVE/LOAD UTILITY\")\n","    print(\"=\" * 40)\n","\n","    # Show examples\n","    example_save_workflow()\n","    example_load_workflow()\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"READY-TO-USE CODE FOR YOUR SITUATION\")\n","    print(\"=\"*60)\n","\n","    print(\"# You currently have:\")\n","    print(\"# train_dataset, test_dataset, train_loader, test_loader = create_datasets_for_training(...)\")\n","    print()\n","    print(\"# To save them:\")\n","    print(\"train_path, test_path = save_datasets_simple(train_dataset, test_dataset)\")\n","    print()\n","    print(\"# To load them later:\")\n","    print(\"train_dataset, test_dataset = load_datasets_simple(train_path, test_path)\")\n","    print(\"train_loader, test_loader = create_dataloaders_from_datasets(train_dataset, test_dataset)\")\n","    print()\n","    print(\"# To see what you have saved:\")\n","    print(\"list_saved_datasets()\")"],"metadata":{"id":"TF3ixeNawzh_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## save dataset"],"metadata":{"id":"xsazbNY82t_V"}},{"cell_type":"code","source":["train_path, test_path = save_datasets_simple(train_dataset, test_dataset, './my_datasets/')"],"metadata":{"id":"6vWRoINN2Oww"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## loaded dataset (not useful if we generate the data)"],"metadata":{"id":"J-bN39UnBaoS"}},{"cell_type":"code","source":["# Save and Load Existing Visual Memory Datasets\n","import torch\n","import pickle\n","import os\n","from datetime import datetime\n","\n","\n","def save_datasets_simple(train_dataset, test_dataset, save_dir='./my_datasets/'):\n","    \"\"\"Simple way to save your existing datasets\"\"\"\n","\n","    # Create directory if it doesn't exist\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    # Create descriptive filenames\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","    train_size = len(train_dataset)\n","    test_size = len(test_dataset)\n","    num_distractors = train_dataset.num_distractors\n","\n","    train_filename = f'train_{train_size}samples_{num_distractors}dist_{timestamp}.pkl'\n","    test_filename = f'test_{test_size}samples_{num_distractors}dist_{timestamp}.pkl'\n","\n","    train_path = os.path.join(save_dir, train_filename)\n","    test_path = os.path.join(save_dir, test_filename)\n","\n","    print(f\"Saving datasets to {save_dir}\")\n","    print(f\"Training dataset: {train_filename}\")\n","    print(f\"Test dataset: {test_filename}\")\n","\n","    # Save training dataset\n","    print(\"Saving training dataset...\")\n","    with open(train_path, 'wb') as f:\n","        pickle.dump({\n","            'samples': train_dataset.samples,\n","            'labels': train_dataset.labels,\n","            'metadata': train_dataset.metadata,\n","            'num_samples': train_dataset.num_samples,\n","            'num_distractors': train_dataset.num_distractors,\n","            'noise_types': train_dataset.noise_types,\n","            'match_probability': train_dataset.match_probability,\n","            'creation_time': datetime.now().isoformat(),\n","            'dataset_type': 'training'\n","        }, f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    # Save test dataset\n","    print(\"Saving test dataset...\")\n","    with open(test_path, 'wb') as f:\n","        pickle.dump({\n","            'samples': test_dataset.samples,\n","            'labels': test_dataset.labels,\n","            'metadata': test_dataset.metadata,\n","            'num_samples': test_dataset.num_samples,\n","            'num_distractors': test_dataset.num_distractors,\n","            'noise_types': test_dataset.noise_types,\n","            'match_probability': test_dataset.match_probability,\n","            'creation_time': datetime.now().isoformat(),\n","            'dataset_type': 'testing'\n","        }, f, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","    # Print file sizes\n","    train_size_mb = os.path.getsize(train_path) / (1024 * 1024)\n","    test_size_mb = os.path.getsize(test_path) / (1024 * 1024)\n","\n","    print(f\"‚úÖ Datasets saved successfully!\")\n","    print(f\"Training dataset: {train_size_mb:.1f} MB\")\n","    print(f\"Test dataset: {test_size_mb:.1f} MB\")\n","    print(f\"Total size: {train_size_mb + test_size_mb:.1f} MB\")\n","\n","    return train_path, test_path\n","\n","def load_datasets_simple(train_path, test_path):\n","    \"\"\"Simple way to load your saved datasets\"\"\"\n","\n","    print(f\"Loading datasets...\")\n","    print(f\"Training: {train_path}\")\n","    print(f\"Test: {test_path}\")\n","\n","    # Check if files exist\n","    if not os.path.exists(train_path):\n","        raise FileNotFoundError(f\"Training dataset not found: {train_path}\")\n","    if not os.path.exists(test_path):\n","        raise FileNotFoundError(f\"Test dataset not found: {test_path}\")\n","\n","    # Load training dataset\n","    print(\"Loading training dataset...\")\n","    with open(train_path, 'rb') as f:\n","        train_data = pickle.load(f)\n","\n","    # Load test dataset\n","    print(\"Loading test dataset...\")\n","    with open(test_path, 'rb') as f:\n","        test_data = pickle.load(f)\n","\n","    # Create dataset objects\n","    train_dataset = SimpleVisualMemoryDataset(train_data)\n","    test_dataset = SimpleVisualMemoryDataset(test_data)\n","\n","    # Print info\n","    print(f\"‚úÖ Datasets loaded successfully!\")\n","    print(f\"Training: {len(train_dataset)} samples\")\n","    print(f\"Test: {len(test_dataset)} samples\")\n","    print(f\"Distractors: {train_dataset.num_distractors}\")\n","    print(f\"Creation time: {train_data.get('creation_time', 'Unknown')}\")\n","\n","    return train_dataset, test_dataset\n","\n","class SimpleVisualMemoryDataset:\n","    \"\"\"Simple dataset class for loaded data\"\"\"\n","    def __init__(self, data_dict):\n","        self.samples = data_dict['samples']\n","        self.labels = data_dict['labels']\n","        self.metadata = data_dict['metadata']\n","        self.num_samples = data_dict['num_samples']\n","        self.num_distractors = data_dict['num_distractors']\n","        self.noise_types = data_dict['noise_types']\n","        self.match_probability = data_dict['match_probability']\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, idx):\n","        return self.samples[idx], self.labels[idx]\n","\n","    def get_sample_with_metadata(self, idx):\n","        return self.samples[idx], self.labels[idx], self.metadata[idx]\n","\n","# =============================================================================\n","# OPTION 2: USING DATASET'S BUILT-IN SAVE METHOD\n","# =============================================================================\n","\n","def save_datasets_builtin(train_dataset, test_dataset, save_dir='./my_datasets/'):\n","    \"\"\"Use the dataset's built-in save method (if available)\"\"\"\n","\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    # Generate filenames\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","    train_size = len(train_dataset)\n","    test_size = len(test_dataset)\n","    num_distractors = train_dataset.num_distractors\n","\n","    train_path = os.path.join(save_dir, f'train_{train_size}_{num_distractors}dist_{timestamp}.pkl')\n","    test_path = os.path.join(save_dir, f'test_{test_size}_{num_distractors}dist_{timestamp}.pkl')\n","\n","    # Use built-in save method if your dataset has it\n","    if hasattr(train_dataset, 'save_dataset'):\n","        print(\"Using built-in save method...\")\n","        train_dataset.save_dataset(train_path)\n","        test_dataset.save_dataset(test_path)\n","    else:\n","        print(\"No built-in save method, using simple save...\")\n","        return save_datasets_simple(train_dataset, test_dataset, save_dir)\n","\n","    return train_path, test_path\n","\n","# =============================================================================\n","# CONVENIENCE FUNCTIONS\n","# =============================================================================\n","\n","def quick_save(train_dataset, test_dataset, name=\"my_experiment\"):\n","    \"\"\"Quick save with a custom name\"\"\"\n","\n","    save_dir = f'./saved_datasets/{name}/'\n","    os.makedirs(save_dir, exist_ok=True)\n","\n","    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n","    train_path = os.path.join(save_dir, f'train_{timestamp}.pkl')\n","    test_path = os.path.join(save_dir, f'test_{timestamp}.pkl')\n","\n","    # Save datasets\n","    with open(train_path, 'wb') as f:\n","        pickle.dump(train_dataset, f)\n","\n","    with open(test_path, 'wb') as f:\n","        pickle.dump(test_dataset, f)\n","\n","    print(f\"‚úÖ Quick save completed!\")\n","    print(f\"Saved to: {save_dir}\")\n","    print(f\"Training: train_{timestamp}.pkl\")\n","    print(f\"Test: test_{timestamp}.pkl\")\n","\n","    return train_path, test_path\n","\n","def quick_load(train_path, test_path):\n","    \"\"\"Quick load datasets\"\"\"\n","\n","    with open(train_path, 'rb') as f:\n","        train_dataset = pickle.load(f)\n","\n","    with open(test_path, 'rb') as f:\n","        test_dataset = pickle.load(f)\n","\n","    print(f\"‚úÖ Quick load completed!\")\n","    print(f\"Training: {len(train_dataset)} samples\")\n","    print(f\"Test: {len(test_dataset)} samples\")\n","\n","    return train_dataset, test_dataset\n","\n","def list_saved_datasets(save_dir='./my_datasets/'):\n","    \"\"\"List all saved datasets in directory\"\"\"\n","\n","    if not os.path.exists(save_dir):\n","        print(f\"Directory {save_dir} doesn't exist\")\n","        return []\n","\n","    pkl_files = [f for f in os.listdir(save_dir) if f.endswith('.pkl')]\n","\n","    if not pkl_files:\n","        print(f\"No .pkl files found in {save_dir}\")\n","        return []\n","\n","    print(f\"Saved datasets in {save_dir}:\")\n","    print(\"=\" * 50)\n","\n","    datasets = []\n","    for file in sorted(pkl_files):\n","        file_path = os.path.join(save_dir, file)\n","        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)\n","        mod_time = os.path.getmtime(file_path)\n","        mod_date = datetime.fromtimestamp(mod_time).strftime('%Y-%m-%d %H:%M:%S')\n","\n","        print(f\"üìÅ {file}\")\n","        print(f\"   Size: {file_size_mb:.1f} MB\")\n","        print(f\"   Modified: {mod_date}\")\n","\n","        datasets.append({\n","            'filename': file,\n","            'path': file_path,\n","            'size_mb': file_size_mb,\n","            'modified': mod_date\n","        })\n","        print()\n","\n","    return datasets\n","\n","# =============================================================================\n","# CREATE DATALOADERS FROM LOADED DATASETS\n","# =============================================================================\n","\n","def create_dataloaders_from_datasets(train_dataset, test_dataset, batch_size=32):\n","    \"\"\"Create DataLoaders from your loaded datasets\"\"\"\n","\n","    from torch.utils.data import DataLoader\n","\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        drop_last=True  # For consistent batch sizes\n","    )\n","\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=batch_size,\n","        shuffle=False,\n","        drop_last=False\n","    )\n","\n","    print(f\"‚úÖ DataLoaders created!\")\n","    print(f\"Training: {len(train_loader)} batches of size {batch_size}\")\n","    print(f\"Test: {len(test_loader)} batches of size {batch_size}\")\n","\n","    return train_loader, test_loader\n","\n","# =============================================================================\n","# COMPLETE WORKFLOW EXAMPLES\n","# =============================================================================\n","\n","def example_save_workflow():\n","    \"\"\"Example: Save your existing datasets\"\"\"\n","\n","    print(\"=\"*60)\n","    print(\"EXAMPLE: SAVE WORKFLOW\")\n","    print(\"=\"*60)\n","\n","    # Assuming you already have your datasets:\n","    # train_dataset, test_dataset, train_loader, test_loader = create_datasets_for_training(...)\n","\n","    print(\"# Step 1: Save your datasets\")\n","    print(\"train_path, test_path = save_datasets_simple(train_dataset, test_dataset, './my_datasets/')\")\n","    print()\n","    print(\"# OR quick save:\")\n","    print(\"train_path, test_path = quick_save(train_dataset, test_dataset, 'experiment_1')\")\n","\n","def example_load_workflow():\n","    \"\"\"Example: Load and use saved datasets\"\"\"\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"EXAMPLE: LOAD WORKFLOW\")\n","    print(\"=\"*60)\n","\n","    print(\"# Step 1: List available datasets\")\n","    print(\"list_saved_datasets('./my_datasets/')\")\n","    print()\n","    print(\"# Step 2: Load specific datasets\")\n","    print(\"train_dataset, test_dataset = load_datasets_simple(\")\n","    print(\"    './my_datasets/train_1000samples_3dist_20241223_1430.pkl',\")\n","    print(\"    './my_datasets/test_300samples_3dist_20241223_1430.pkl'\")\n","    print(\")\")\n","    print()\n","    print(\"# Step 3: Create DataLoaders\")\n","    print(\"train_loader, test_loader = create_dataloaders_from_datasets(\")\n","    print(\"    train_dataset, test_dataset, batch_size=32\")\n","    print(\")\")\n","    print()\n","    print(\"# Step 4: Start training!\")\n","    print(\"# Now you can use train_loader and test_loader for training\")\n","\n","# =============================================================================\n","# READY-TO-USE EXAMPLE\n","# =============================================================================\n","\n","if __name__ == \"__main__\":\n","    print(\"DATASET SAVE/LOAD UTILITY\")\n","    print(\"=\" * 40)\n","\n","    # Show examples\n","    example_save_workflow()\n","    example_load_workflow()\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"READY-TO-USE CODE FOR YOUR SITUATION\")\n","    print(\"=\"*60)\n","\n","    print(\"# You currently have:\")\n","    print(\"# train_dataset, test_dataset, train_loader, test_loader = create_datasets_for_training(...)\")\n","    print()\n","    print(\"# To save them:\")\n","    print(\"train_path, test_path = save_datasets_simple(train_dataset, test_dataset)\")\n","    print()\n","    print(\"# To load them later:\")\n","    print(\"train_dataset, test_dataset = load_datasets_simple(train_path, test_path)\")\n","    print(\"train_loader, test_loader = create_dataloaders_from_datasets(train_dataset, test_dataset)\")\n","    print()\n","    print(\"# To see what you have saved:\")\n","    print(\"list_saved_datasets()\")"],"metadata":{"id":"HN2h3N9qBcqq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## dataset download"],"metadata":{"id":"iYX-aL_NFu4R"}},{"cell_type":"code","source":["import os\n","folder_name = 'my_datasets'\n","file_list = os.listdir(folder_name)\n","print(file_list)"],"metadata":{"id":"1b6ZzlSGVEI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_path = './my_datasets/train_5000samples_3dist_20250724_2358.pkl'\n","test_path = './my_datasets/test_1000samples_3dist_20250724_2358.pkl'\n","\n","train_dataset, test_dataset = load_datasets_simple(train_path, test_path)\n","train_loader, test_loader = create_dataloaders_from_datasets(train_dataset, test_dataset)"],"metadata":{"id":"YwXe9VJtBy3d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## visual function"],"metadata":{"id":"v20zwXDNb-8H"}},{"cell_type":"code","source":["def plot_training_history(train_losses, train_accs, test_losses, test_accs,\n","                         train_match_accs, train_nomatch_accs,\n","                         test_match_accs, test_nomatch_accs):\n","    \"\"\"Plot comprehensive training history\"\"\"\n","\n","    epochs = range(1, len(train_losses) + 1)\n","\n","    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n","    fig.suptitle('Visual Memory Task Training History', fontsize=16)\n","\n","    # Loss plot\n","    axes[0, 0].plot(epochs, train_losses, 'b-', label='Train Loss', marker='o')\n","    axes[0, 0].plot(epochs, test_losses, 'r-', label='Test Loss', marker='s')\n","    axes[0, 0].set_title('Loss Over Time')\n","    axes[0, 0].set_xlabel('Epoch')\n","    axes[0, 0].set_ylabel('Loss')\n","    axes[0, 0].legend()\n","    axes[0, 0].grid(True, alpha=0.3)\n","\n","    # Overall accuracy plot\n","    axes[0, 1].plot(epochs, train_accs, 'b-', label='Train Accuracy', marker='o')\n","    axes[0, 1].plot(epochs, test_accs, 'r-', label='Test Accuracy', marker='s')\n","    axes[0, 1].set_title('Overall Accuracy')\n","    axes[0, 1].set_xlabel('Epoch')\n","    axes[0, 1].set_ylabel('Accuracy (%)')\n","    axes[0, 1].legend()\n","    axes[0, 1].grid(True, alpha=0.3)\n","\n","    # Match trial accuracy\n","    axes[1, 0].plot(epochs, train_match_accs, 'g-', label='Train Match', marker='o')\n","    axes[1, 0].plot(epochs, test_match_accs, 'darkgreen', label='Test Match', marker='s')\n","    axes[1, 0].set_title('Match Trial Accuracy')\n","    axes[1, 0].set_xlabel('Epoch')\n","    axes[1, 0].set_ylabel('Accuracy (%)')\n","    axes[1, 0].legend()\n","    axes[1, 0].grid(True, alpha=0.3)\n","\n","    # No-match trial accuracy\n","    axes[1, 1].plot(epochs, train_nomatch_accs, 'orange', label='Train No-Match', marker='o')\n","    axes[1, 1].plot(epochs, test_nomatch_accs, 'red', label='Test No-Match', marker='s')\n","    axes[1, 1].set_title('No-Match Trial Accuracy')\n","    axes[1, 1].set_xlabel('Epoch')\n","    axes[1, 1].set_ylabel('Accuracy (%)')\n","    axes[1, 1].legend()\n","    axes[1, 1].grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","def plot_confusion_matrix(predictions, targets, epoch):\n","    \"\"\"Plot confusion matrix\"\"\"\n","    cm = confusion_matrix(targets, predictions)\n","\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","                xticklabels=['No Match', 'Match'],\n","                yticklabels=['No Match', 'Match'])\n","    plt.title(f'Confusion Matrix - Epoch {epoch}')\n","    plt.xlabel('Predicted Label')\n","    plt.ylabel('True Label')\n","    plt.show()\n","\n","    # Print classification report\n","    print(f\"\\nClassification Report - Epoch {epoch}:\")\n","    print(classification_report(targets, predictions,\n","                              target_names=['No Match', 'Match']))\n","\n","def visualize_model_predictions(model, test_dataset, device, num_samples=6):\n","    \"\"\"Visualize model predictions on test samples\"\"\"\n","    model.eval()\n","\n","    fig, axes = plt.subplots(num_samples, 6, figsize=(15, num_samples * 2.5))\n","    if num_samples == 1:\n","        axes = axes.reshape(1, -1)\n","\n","    fig.suptitle('Model Predictions on Test Samples', fontsize=16)\n","\n","    indices = np.random.choice(len(test_dataset), num_samples, replace=False)\n","\n","    with torch.no_grad():\n","        for i, idx in enumerate(indices):\n","            sequence, true_label, metadata = test_dataset.get_sample_with_metadata(idx)\n","\n","            # Get model prediction\n","            sequence_batch = sequence.unsqueeze(0).to(device)  # Add batch dimension\n","            output = model(sequence_batch)\n","            probabilities = F.softmax(output, dim=1)\n","            predicted_label = output.argmax(1).item()\n","            confidence = probabilities[0][predicted_label].item()\n","\n","            # Get attention weights\n","            try:\n","                attention_weights = model.get_attention_weights(sequence_batch)[0].cpu().numpy()\n","            except:\n","                attention_weights = np.ones(sequence.shape[0]) / sequence.shape[0]  # Uniform if error\n","\n","            seq_len = sequence.shape[0]\n","            target_digit = metadata['target_digit']\n","            probe_digit = metadata['probe_digit']\n","\n","            print(f\"\\nSample {i+1}:\")\n","            print(f\"  Target: {target_digit}, Probe: {probe_digit}\")\n","            print(f\"  True: {'MATCH' if true_label == 1 else 'NO MATCH'}\")\n","            print(f\"  Predicted: {'MATCH' if predicted_label == 1 else 'NO MATCH'} (conf: {confidence:.3f})\")\n","            print(f\"  Attention weights: {attention_weights}\")\n","\n","            # Display sequence\n","            for j in range(min(seq_len, 6)):\n","                ax = axes[i, j]\n","                img = sequence[j].squeeze().numpy()\n","                ax.imshow(img, cmap='gray')\n","                ax.axis('off')\n","\n","                # Add attention-based border\n","                alpha = attention_weights[j] if j < len(attention_weights) else 0.1\n","                border_width = int(alpha * 5) + 1\n","\n","                if j == 0:\n","                    ax.set_title(f'TARGET\\n(att: {alpha:.2f})', color='blue', fontweight='bold')\n","                    ax.add_patch(plt.Rectangle((0, 0), 27, 27, fill=False,\n","                                             edgecolor='blue', linewidth=border_width))\n","                elif j == seq_len - 1:\n","                    color = 'green' if predicted_label == true_label else 'red'\n","                    pred_text = 'MATCH' if predicted_label == 1 else 'NO MATCH'\n","                    ax.set_title(f'PROBE\\n{pred_text}\\n(att: {alpha:.2f})',\n","                               color=color, fontweight='bold')\n","                    ax.add_patch(plt.Rectangle((0, 0), 27, 27, fill=False,\n","                                             edgecolor=color, linewidth=border_width))\n","                else:\n","                    ax.set_title(f'NOISE {j}\\n(att: {alpha:.2f})', color='gray')\n","\n","            # Hide unused subplots\n","            for j in range(seq_len, 6):\n","                axes[i, j].axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n"],"metadata":{"id":"Y6gKZhu0bYb3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## mean function"],"metadata":{"id":"o4UokMcGcCN4"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tqdm import tqdm\n","import time\n","import os\n","from sklearn.metrics import confusion_matrix, classification_report\n","import seaborn as sns\n","\n","# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")\n","\n","class SimpleCNN(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(SimpleCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.dropout1 = nn.Dropout(0.25)\n","        self.dropout2 = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n","        self.fc2 = nn.Linear(512, num_classes)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = self.pool(x)\n","        x = F.relu(self.conv2(x))\n","        x = self.pool(x)\n","        x = F.relu(self.conv3(x))\n","        x = self.dropout1(x)\n","        x = x.view(x.size(0), -1)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        return x\n","\n","    def extract_features(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = self.pool(x)\n","        x = F.relu(self.conv2(x))\n","        x = self.pool(x)\n","        x = F.relu(self.conv3(x))\n","        x = self.dropout1(x)\n","        x = x.view(x.size(0), -1)\n","        x = F.relu(self.fc1(x))\n","\n","        return x\n","\n","class CNNFeatureExtractor(nn.Module):\n","    def __init__(self, pretrained_cnn_path, feature_dim=512):\n","        super(CNNFeatureExtractor, self).__init__()\n","\n","        self.cnn = SimpleCNN()\n","        self.cnn.load_state_dict(torch.load(pretrained_cnn_path, map_location=device))\n","\n","        for param in self.cnn.parameters():\n","            param.requires_grad = False\n","\n","        self.cnn.eval()\n","        self.feature_dim = feature_dim\n","\n","    def forward(self, x):\n","        with torch.no_grad():\n","            features = self.cnn.extract_features(x)\n","        return features\n","\n","\n","class VisualMemoryModel(nn.Module):\n","    def __init__(self, pretrained_cnn_path, rnn_hidden_dim=256,\n","                 projection_dim=128, rnn_type='LSTM', num_layers=2, dropout=0.3):\n","        super(VisualMemoryModel, self).__init__()\n","\n","        self.cnn_features = CNNFeatureExtractor(pretrained_cnn_path)\n","        cnn_feature_dim = self.cnn_features.feature_dim\n","\n","        self.feature_projection = nn.Sequential(\n","            nn.Linear(cnn_feature_dim, projection_dim * 2),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(projection_dim * 2, projection_dim),\n","            nn.ReLU(),\n","            nn.Dropout(dropout * 0.5)\n","        )\n","\n","        self.rnn_type = rnn_type\n","        if rnn_type == 'LSTM':\n","            self.rnn = nn.LSTM(\n","                projection_dim, rnn_hidden_dim,\n","                num_layers=num_layers,\n","                batch_first=True,\n","                dropout=dropout if num_layers > 1 else 0,\n","                bidirectional=False\n","            )\n","        elif rnn_type == 'GRU':\n","            self.rnn = nn.GRU(\n","                projection_dim, rnn_hidden_dim,\n","                num_layers=num_layers,\n","                batch_first=True,\n","                dropout=dropout if num_layers > 1 else 0,\n","                bidirectional=False\n","            )\n","\n","        self.memory_classifier = nn.Sequential(\n","            nn.Linear(rnn_hidden_dim, rnn_hidden_dim // 2),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(rnn_hidden_dim // 2, 64),\n","            nn.ReLU(),\n","            nn.Dropout(dropout * 0.5),\n","            nn.Linear(64, 2)\n","        )\n","\n","        self.rnn_hidden_dim = rnn_hidden_dim\n","        self.num_layers = num_layers\n","        self.projection_dim = projection_dim\n","\n","    def forward(self, x):\n","        batch_size, seq_len = x.size(0), x.size(1)\n","        x = x.view(batch_size * seq_len, *x.shape[2:])\n","        cnn_features = self.cnn_features(x)\n","        projected_features = self.feature_projection(cnn_features)\n","        projected_features = projected_features.view(batch_size, seq_len, -1)\n","\n","        if self.rnn_type == 'LSTM':\n","            rnn_output, (hidden, cell) = self.rnn(projected_features)\n","        else:\n","            rnn_output, hidden = self.rnn(projected_features)\n","\n","        final_output = rnn_output[:, -1, :]\n","        logits = self.memory_classifier(final_output)\n","        return logits\n","\n","    def get_attention_weights(self, x):\n","        \"\"\"Get attention-like weights to see what the model focuses on\"\"\"\n","        batch_size, seq_len = x.size(0), x.size(1)\n","\n","        x = x.view(batch_size * seq_len, *x.shape[2:])\n","        cnn_features = self.cnn_features(x)\n","        projected_features = self.feature_projection(cnn_features)\n","        projected_features = projected_features.view(batch_size, seq_len, -1)\n","\n","        if self.rnn_type == 'LSTM':\n","            rnn_output, _ = self.rnn(projected_features)\n","        else:\n","            rnn_output, _ = self.rnn(projected_features)\n","\n","        final_state = rnn_output[:, -1:, :]  # [batch_size, 1, hidden_dim]\n","        attention_scores = torch.bmm(rnn_output, final_state.transpose(1, 2))  # [batch_size, seq_len, 1]\n","        attention_weights = F.softmax(attention_scores.squeeze(-1), dim=1)  # [batch_size, seq_len]\n","        return attention_weights\n","\n","def train_memory_model(model, train_loader, criterion, optimizer, device, epoch):\n","    \"\"\"Train the model for one epoch\"\"\"\n","    model.train()\n","    model.cnn_features.eval()\n","\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    match_correct = 0\n","    match_total = 0\n","    nomatch_correct = 0\n","    nomatch_total = 0\n","\n","    train_bar = tqdm(train_loader, desc=f'Epoch {epoch} Training')\n","\n","    for batch_idx, (sequences, targets) in enumerate(train_bar):\n","        sequences, targets = sequences.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(sequences)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","\n","\n","        running_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","        # Separate accuracy for match vs no-match\n","        match_mask = (targets == 1)\n","        nomatch_mask = (targets == 0)\n","\n","        if match_mask.sum() > 0:\n","            match_correct += predicted[match_mask].eq(targets[match_mask]).sum().item()\n","            match_total += match_mask.sum().item()\n","\n","        if nomatch_mask.sum() > 0:\n","            nomatch_correct += predicted[nomatch_mask].eq(targets[nomatch_mask]).sum().item()\n","            nomatch_total += nomatch_mask.sum().item()\n","\n","\n","        train_bar.set_postfix({\n","            'Loss': f'{running_loss/(batch_idx+1):.4f}',\n","            'Acc': f'{100.*correct/total:.2f}%',\n","            'M': f'{100.*match_correct/max(match_total,1):.1f}%',\n","            'NM': f'{100.*nomatch_correct/max(nomatch_total,1):.1f}%'\n","        })\n","\n","    epoch_loss = running_loss / len(train_loader)\n","    epoch_acc = 100. * correct / total\n","    match_acc = 100. * match_correct / max(match_total, 1)\n","    nomatch_acc = 100. * nomatch_correct / max(nomatch_total, 1)\n","\n","    return epoch_loss, epoch_acc, match_acc, nomatch_acc\n","\n","def test_memory_model(model, test_loader, criterion, device, epoch):\n","    \"\"\"Test the model\"\"\"\n","    model.eval()\n","    test_loss = 0.0\n","    correct = 0\n","    total = 0\n","    match_correct = 0\n","    match_total = 0\n","    nomatch_correct = 0\n","    nomatch_total = 0\n","\n","    all_predictions = []\n","    all_targets = []\n","\n","    with torch.no_grad():\n","        test_bar = tqdm(test_loader, desc=f'Epoch {epoch} Testing')\n","\n","        for sequences, targets in test_bar:\n","            sequences, targets = sequences.to(device), targets.to(device)\n","\n","            outputs = model(sequences)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","            all_predictions.extend(predicted.cpu().numpy())\n","            all_targets.extend(targets.cpu().numpy())\n","\n","            match_mask = (targets == 1)\n","            nomatch_mask = (targets == 0)\n","\n","            if match_mask.sum() > 0:\n","                match_correct += predicted[match_mask].eq(targets[match_mask]).sum().item()\n","                match_total += match_mask.sum().item()\n","\n","            if nomatch_mask.sum() > 0:\n","                nomatch_correct += predicted[nomatch_mask].eq(targets[nomatch_mask]).sum().item()\n","                nomatch_total += nomatch_mask.sum().item()\n","\n","            test_bar.set_postfix({\n","                'Loss': f'{test_loss/len(test_loader):.4f}',\n","                'Acc': f'{100.*correct/total:.2f}%'\n","            })\n","\n","    epoch_loss = test_loss / len(test_loader)\n","    epoch_acc = 100. * correct / total\n","    match_acc = 100. * match_correct / max(match_total, 1)\n","    nomatch_acc = 100. * nomatch_correct / max(nomatch_total, 1)\n","\n","    return epoch_loss, epoch_acc, match_acc, nomatch_acc, all_predictions, all_targets\n"],"metadata":{"id":"WrmxllXcZXDp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class VanillaRNNVisualMemoryModel(nn.Module):\n","    def __init__(self, pretrained_cnn_path, rnn_hidden_dim=256,\n","                 projection_dim=128, num_layers=2, dropout=0.3):\n","        super(VanillaRNNVisualMemoryModel, self).__init__()\n","\n","        # Frozen CNN feature extractor (same as before)\n","        self.cnn_features = CNNFeatureExtractor(pretrained_cnn_path)\n","        cnn_feature_dim = self.cnn_features.feature_dim  # 512\n","\n","        # Trainable feature projection\n","        self.feature_projection = nn.Sequential(\n","            nn.Linear(cnn_feature_dim, projection_dim * 2),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(projection_dim * 2, projection_dim),\n","            nn.ReLU(),\n","            nn.Dropout(dropout * 0.5)\n","        )\n","\n","        # VANILLA RNN (key difference!)\n","        self.rnn_type = 'Vanilla'\n","        self.num_layers = num_layers\n","        self.rnn_hidden_dim = rnn_hidden_dim\n","\n","        # Stack of vanilla RNN layers\n","        self.rnn_layers = nn.ModuleList()\n","\n","        # First layer: input_size = projection_dim\n","        self.rnn_layers.append(\n","            nn.RNN(projection_dim, rnn_hidden_dim, num_layers=1,\n","                   batch_first=True, nonlinearity='tanh')\n","        )\n","\n","        # Additional layers (if num_layers > 1)\n","        for _ in range(num_layers - 1):\n","            self.rnn_layers.append(\n","                nn.RNN(rnn_hidden_dim, rnn_hidden_dim, num_layers=1,\n","                       batch_first=True, nonlinearity='tanh')\n","            )\n","\n","        # Dropout between layers\n","        self.rnn_dropout = nn.Dropout(dropout)\n","\n","        # Memory comparison and classification head\n","        self.memory_classifier = nn.Sequential(\n","            nn.Linear(rnn_hidden_dim, rnn_hidden_dim // 2),\n","            nn.ReLU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(rnn_hidden_dim // 2, 64),\n","            nn.ReLU(),\n","            nn.Dropout(dropout * 0.5),\n","            nn.Linear(64, 2)  # Binary: match (1) vs no-match (0)\n","        )\n","\n","        self.projection_dim = projection_dim\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Args:\n","            x: [batch_size, seq_len, channels, height, width]\n","        Returns:\n","            output: [batch_size, 2] logits for match/no-match classification\n","        \"\"\"\n","        batch_size, seq_len = x.size(0), x.size(1)\n","\n","        # Reshape to process all images at once\n","        x = x.view(batch_size * seq_len, *x.shape[2:])\n","\n","        # Extract CNN features (frozen)\n","        cnn_features = self.cnn_features(x)  # [batch_size * seq_len, 512]\n","\n","        # Project to lower dimension (trainable)\n","        projected_features = self.feature_projection(cnn_features)  # [batch_size * seq_len, projection_dim]\n","\n","        # Reshape for RNN processing\n","        projected_features = projected_features.view(batch_size, seq_len, -1)  # [batch_size, seq_len, projection_dim]\n","\n","        # Process through stacked vanilla RNN layers\n","        rnn_input = projected_features\n","\n","        for i, rnn_layer in enumerate(self.rnn_layers):\n","            rnn_output, hidden = rnn_layer(rnn_input)\n","\n","            # Apply dropout between layers (except last layer)\n","            if i < len(self.rnn_layers) - 1:\n","                rnn_output = self.rnn_dropout(rnn_output)\n","\n","            rnn_input = rnn_output\n","\n","        # Use the final output for classification\n","        final_output = rnn_output[:, -1, :]  # [batch_size, rnn_hidden_dim]\n","\n","        # Binary classification: match vs no-match\n","        logits = self.memory_classifier(final_output)  # [batch_size, 2]\n","\n","        return logits\n","\n","    def get_hidden_states(self, x):\n","        \"\"\"Get hidden states at each timestep for analysis\"\"\"\n","        batch_size, seq_len = x.size(0), x.size(1)\n","\n","        x = x.view(batch_size * seq_len, *x.shape[2:])\n","        cnn_features = self.cnn_features(x)\n","        projected_features = self.feature_projection(cnn_features)\n","        projected_features = projected_features.view(batch_size, seq_len, -1)\n","\n","        # Process through RNN layers to get final hidden states\n","        rnn_input = projected_features\n","\n","        for rnn_layer in self.rnn_layers:\n","            rnn_output, _ = rnn_layer(rnn_input)\n","            rnn_input = rnn_output\n","\n","        return rnn_output, projected_features"],"metadata":{"id":"jrh1vIF2Y-Sk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_visual_memory_model(train_loader, test_loader, test_dataset,\n","                             pretrained_cnn_path,rnn_type='GRU', num_epochs=15,\n","                             learning_rate=0.001, save_path='visual_memory_model_GRU.pth'):\n","\n","    print(\"=\"*60)\n","    print(\"VISUAL MEMORY TASK TRAINING\")\n","    print(\"=\"*60)\n","\n","    if rnn_type == 'Vanilla':\n","        model = VanillaRNNVisualMemoryModel(\n","            pretrained_cnn_path=pretrained_cnn_path,\n","            rnn_hidden_dim=256,\n","            projection_dim=128,\n","            num_layers=2,\n","            dropout=0.3\n","        ).to(device)\n","\n","    elif rnn_type == 'RIM':\n","        model = RIMVisualMemoryModel(\n","            pretrained_cnn_path=pretrained_cnn_path,\n","            rim_hidden_dim=256,        # Hidden dimension per unit\n","            projection_dim=128,\n","            num_units=6,               # Total number of mechanisms\n","            k_active_units=3,          # Active mechanisms per timestep\n","            num_layers=2,\n","            unit_type='LSTM',          # 'LSTM', 'GRU', or 'Vanilla'\n","            dropout=0.3\n","        )\n","    else:\n","      model = VisualMemoryModel(\n","          pretrained_cnn_path=pretrained_cnn_path,\n","          rnn_hidden_dim=256,\n","          projection_dim=128,\n","          rnn_type=rnn_type,\n","          num_layers=2,\n","          dropout=0.3\n","      ).to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(\n","        filter(lambda p: p.requires_grad, model.parameters()),\n","        lr=learning_rate,\n","        weight_decay=1e-4\n","    )\n","\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, mode='max', factor=0.5, patience=3, verbose=True\n","    )\n","\n","    train_losses = []\n","    train_accs = []\n","    test_losses = []\n","    test_accs = []\n","    train_match_accs = []\n","    train_nomatch_accs = []\n","    test_match_accs = []\n","    test_nomatch_accs = []\n","\n","    best_test_acc = 0.0\n","    best_model_state = None\n","\n","    print(f\"\\nStarting training for {num_epochs} epochs...\")\n","    start_time = time.time()\n","\n","    for epoch in range(1, num_epochs + 1):\n","        print(f\"\\nEpoch {epoch}/{num_epochs}\")\n","        print(\"-\" * 40)\n","\n","        train_loss, train_acc, train_match_acc, train_nomatch_acc = train_memory_model(\n","            model, train_loader, criterion, optimizer, device, epoch\n","        )\n","\n","        test_loss, test_acc, test_match_acc, test_nomatch_acc, predictions, targets = test_memory_model(\n","            model, test_loader, criterion, device, epoch\n","        )\n","\n","        scheduler.step(test_acc)\n","\n","        train_losses.append(train_loss)\n","        train_accs.append(train_acc)\n","        test_losses.append(test_loss)\n","        test_accs.append(test_acc)\n","        train_match_accs.append(train_match_acc)\n","        train_nomatch_accs.append(train_nomatch_acc)\n","        test_match_accs.append(test_match_acc)\n","        test_nomatch_accs.append(test_nomatch_acc)\n","\n","        if test_acc > best_test_acc:\n","            best_test_acc = test_acc\n","            best_model_state = model.state_dict().copy()\n","\n","        print(f\"Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%, \"\n","              f\"Match: {train_match_acc:.2f}%, No-Match: {train_nomatch_acc:.2f}%\")\n","        print(f\"Test  - Loss: {test_loss:.4f}, Acc: {test_acc:.2f}%, \"\n","              f\"Match: {test_match_acc:.2f}%, No-Match: {test_nomatch_acc:.2f}%\")\n","\n","        if epoch % 5 == 0:\n","            plot_confusion_matrix(predictions, targets, epoch)\n","\n","    training_time = time.time() - start_time\n","    print(f\"\\nTraining completed in {training_time:.1f} seconds\")\n","\n","\n","    torch.save(best_model_state, save_path)\n","    print(f\"Best model saved to {save_path} (Test Acc: {best_test_acc:.2f}%)\")\n","\n","    plot_training_history(train_losses, train_accs, test_losses, test_accs,\n","                         train_match_accs, train_nomatch_accs,\n","                         test_match_accs, test_nomatch_accs)\n","\n","    model.load_state_dict(best_model_state)\n","    visualize_model_predictions(model, test_dataset, device, num_samples=1)\n","\n","    print(f\"\\n\" + \"=\"*60)\n","    print(\"FINAL RESULTS\")\n","    print(\"=\"*60)\n","    print(f\"Best Test Accuracy: {best_test_acc:.2f}%\")\n","    print(f\"Final Test Match Accuracy: {test_match_accs[-1]:.2f}%\")\n","    print(f\"Final Test No-Match Accuracy: {test_nomatch_accs[-1]:.2f}%\")\n","    print(f\"Training Time: {training_time:.1f} seconds\")\n","\n","    return model, {\n","        'train_losses': train_losses,\n","        'train_accs': train_accs,\n","        'test_losses': test_losses,\n","        'test_accs': test_accs,\n","        'best_test_acc': best_test_acc\n","    }\n"],"metadata":{"id":"Yl7SXZLAfJ6Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## train"],"metadata":{"id":"wf-3u7Sz3BGC"}},{"cell_type":"code","source":["model, history = train_visual_memory_model(\n","        train_loader=train_loader,\n","        test_loader=test_loader,\n","        test_dataset=test_dataset,\n","        pretrained_cnn_path='small_cnn_model.pth',\n","        rnn_type='GRU',\n","        num_epochs=20,\n","        learning_rate=0.001,\n","        save_path='RNN_model/visual_memory_GRU_noise3.pth'\n","    )"],"metadata":{"id":"AcAAM8QJQUdQ"},"execution_count":null,"outputs":[]}]}