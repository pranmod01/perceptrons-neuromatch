{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pe85TzhLQztl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "846f2a04-aa48-4dc4-92c9-6ac2a4fb5587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/Neuromatch_project/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9IlQisF1tjh",
        "outputId": "9acbedfa-8e47-40f1-81c4-7497be2e7f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Neuromatch_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_CREs1KPqmI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd0b213-d4fd-4d61-9524-ade34cfce979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision matplotlib\n",
        "\n",
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model\n",
        "If you want to test model, you can skip this part"
      ],
      "metadata": {
        "id": "lxd8LpKKE0_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size= 128\n",
        "data_path= r'./data'\n",
        "dtype= torch.float\n",
        "\n",
        "# Create the transoform for MNIST dataset to make sure its 28x28, grayscale, a tensor, and vals normalized to fall between 0 and 1\n",
        "transform= transforms.Compose([\n",
        "    transforms.Resize((28,28)),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0,), (1,)),])\n",
        "\n",
        "# Automatically downloads and splits the MNIST dataset\n",
        "mnist_train = datasets.MNIST(data_path, train= True , download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train= False, download=True, transform=transform)\n",
        "\n",
        "#create DataLoaders\n",
        "train_loader= DataLoader(mnist_train , batch_size= batch_size, shuffle=True, drop_last=True)\n",
        "test_loader= DataLoader(mnist_test , batch_size= batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "L1T-bZvh2UYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "VPxeHcLV2m28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "l0EjCjsl2lyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN(num_classes=10).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "p_-0-2lU21JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training and testing function"
      ],
      "metadata": {
        "id": "JcmPO22p248F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    train_bar = tqdm(train_loader, desc='Training')\n",
        "    for batch_idx, (data, target) in enumerate(train_bar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += target.size(0)\n",
        "        correct += predicted.eq(target).sum().item()\n",
        "\n",
        "        train_bar.set_postfix({\n",
        "            'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
        "            'Acc': f'{100.*correct/total:.2f}%'\n",
        "        })\n",
        "\n",
        "    return running_loss / len(train_loader), 100. * correct / total\n",
        "\n",
        "def test_model(model, test_loader, criterion, device):\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_bar = tqdm(test_loader, desc='Testing')\n",
        "        for data, target in test_bar:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, target)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "\n",
        "            test_bar.set_postfix({\n",
        "                'Loss': f'{test_loss/len(test_loader):.4f}',\n",
        "                'Acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "\n",
        "    return test_loss / len(test_loader), 100. * correct / total"
      ],
      "metadata": {
        "id": "oO8XnrXP29Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training process"
      ],
      "metadata": {
        "id": "djG3V2qK3Ii0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "print(\"\\nStarting Training...\")\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
        "\n",
        "    train_loss, train_acc = train_model(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "    test_loss, test_acc = test_model(model, test_loader, criterion, device)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"\\nTraining completed in {end_time - start_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seZ-Jq1i3L5v",
        "outputId": "59f49ada-0521-498f-da33-7eb7d15dc175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Training...\n",
            "\n",
            "Epoch [1/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 468/468 [00:29<00:00, 15.61it/s, Loss=0.2151, Acc=93.19%]\n",
            "Testing: 100%|██████████| 78/78 [00:02<00:00, 26.72it/s, Loss=0.0532, Acc=98.19%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2151, Train Acc: 93.19%\n",
            "Test Loss: 0.0532, Test Acc: 98.19%\n",
            "\n",
            "Epoch [2/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 468/468 [00:18<00:00, 24.84it/s, Loss=0.0604, Acc=98.16%]\n",
            "Testing: 100%|██████████| 78/78 [00:02<00:00, 31.18it/s, Loss=0.0327, Acc=98.91%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0604, Train Acc: 98.16%\n",
            "Test Loss: 0.0327, Test Acc: 98.91%\n",
            "\n",
            "Epoch [3/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 468/468 [00:20<00:00, 22.83it/s, Loss=0.0451, Acc=98.60%]\n",
            "Testing: 100%|██████████| 78/78 [00:03<00:00, 23.90it/s, Loss=0.0310, Acc=98.96%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0451, Train Acc: 98.60%\n",
            "Test Loss: 0.0310, Test Acc: 98.96%\n",
            "\n",
            "Epoch [4/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 468/468 [00:21<00:00, 21.79it/s, Loss=0.0347, Acc=98.92%]\n",
            "Testing: 100%|██████████| 78/78 [00:02<00:00, 28.56it/s, Loss=0.0269, Acc=99.05%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0347, Train Acc: 98.92%\n",
            "Test Loss: 0.0269, Test Acc: 99.05%\n",
            "\n",
            "Epoch [5/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 468/468 [00:19<00:00, 23.78it/s, Loss=0.0283, Acc=99.10%]\n",
            "Testing: 100%|██████████| 78/78 [00:03<00:00, 21.38it/s, Loss=0.0243, Acc=99.18%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0283, Train Acc: 99.10%\n",
            "Test Loss: 0.0243, Test Acc: 99.18%\n",
            "\n",
            "Epoch [6/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 468/468 [00:19<00:00, 23.95it/s, Loss=0.0240, Acc=99.23%]\n",
            "Testing: 100%|██████████| 78/78 [00:02<00:00, 29.31it/s, Loss=0.0249, Acc=99.26%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0240, Train Acc: 99.23%\n",
            "Test Loss: 0.0249, Test Acc: 99.26%\n",
            "\n",
            "Epoch [7/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 468/468 [00:20<00:00, 23.07it/s, Loss=0.0217, Acc=99.34%]\n",
            "Testing: 100%|██████████| 78/78 [00:02<00:00, 29.71it/s, Loss=0.0201, Acc=99.37%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0217, Train Acc: 99.34%\n",
            "Test Loss: 0.0201, Test Acc: 99.37%\n",
            "\n",
            "Epoch [8/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 468/468 [00:19<00:00, 23.81it/s, Loss=0.0197, Acc=99.41%]\n",
            "Testing: 100%|██████████| 78/78 [00:03<00:00, 23.25it/s, Loss=0.0200, Acc=99.34%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0197, Train Acc: 99.41%\n",
            "Test Loss: 0.0200, Test Acc: 99.34%\n",
            "\n",
            "Epoch [9/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 468/468 [00:19<00:00, 24.09it/s, Loss=0.0157, Acc=99.53%]\n",
            "Testing: 100%|██████████| 78/78 [00:02<00:00, 30.46it/s, Loss=0.0207, Acc=99.38%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0157, Train Acc: 99.53%\n",
            "Test Loss: 0.0207, Test Acc: 99.38%\n",
            "\n",
            "Epoch [10/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 468/468 [00:19<00:00, 23.67it/s, Loss=0.0169, Acc=99.45%]\n",
            "Testing: 100%|██████████| 78/78 [00:02<00:00, 29.41it/s, Loss=0.0206, Acc=99.33%]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0169, Train Acc: 99.45%\n",
            "Test Loss: 0.0206, Test Acc: 99.33%\n",
            "\n",
            "Training completed in 238.16 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'small_cnn_model.pth')"
      ],
      "metadata": {
        "id": "-pduyzMd4A8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n"
      ],
      "metadata": {
        "id": "So-5mSVGC4vP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model, load parameter and dataset"
      ],
      "metadata": {
        "id": "lZhWPsRpFNSx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def load_model(model_path, device):\n",
        "    \"\"\"Load the saved model weights\"\"\"\n",
        "    model = SimpleCNN(num_classes=10).to(device)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval()  # Set to evaluation mode\n",
        "    print(f\"Model loaded from {model_path}\")\n",
        "    return model\n",
        "\n",
        "batch_size = 128\n",
        "data_path = r'./data'\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0,), (1,)),\n",
        "])\n",
        "\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "print(f\"Test samples: {len(mnist_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDI3Na-CC7EK",
        "outputId": "99a88319-3e3f-466c-d6f5-e5649ba747ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test samples: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'small_cnn_model.pth' ## change this to the path of weight\n",
        "model = load_model(model_path, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6Q8WYA0FYet",
        "outputId": "0dde1439-b92d-42d4-9817-b24db4ed0762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from small_cnn_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model accuracy on test dataset"
      ],
      "metadata": {
        "id": "ZXFCw4I5GHi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def comprehensive_test(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_bar = tqdm(test_loader, desc='Testing')\n",
        "        for data, target in test_bar:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            outputs = model(data)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "            c = (predicted == target).squeeze()\n",
        "            for i in range(target.size(0)):\n",
        "                label = target[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(target.cpu().numpy())\n",
        "\n",
        "            test_bar.set_postfix({'Acc': f'{100.*correct/total:.2f}%'})\n",
        "\n",
        "    overall_accuracy = 100. * correct / total\n",
        "\n",
        "    print(f\"\\nOverall Test Accuracy: {overall_accuracy:.2f}%\")\n",
        "    print(\"\\nPer-class Accuracy:\")\n",
        "    for i in range(10):\n",
        "        if class_total[i] > 0:\n",
        "            accuracy = 100 * class_correct[i] / class_total[i]\n",
        "            print(f'Class {i}: {accuracy:.2f}')\n",
        "\n",
        "    return overall_accuracy, all_predictions, all_labels"
      ],
      "metadata": {
        "id": "Q0kpFtBXF1lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_test, all_predictions, all_labels = comprehensive_test(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mgu0cEDfF-ey",
        "outputId": "fea6bb4b-4459-479f-b039-6cac02e0bede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 79/79 [00:03<00:00, 24.35it/s, Acc=99.33%]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall Test Accuracy: 99.33%\n",
            "\n",
            "Per-class Accuracy:\n",
            "Class 0: 99.80\n",
            "Class 1: 99.82\n",
            "Class 2: 99.81\n",
            "Class 3: 99.50\n",
            "Class 4: 99.59\n",
            "Class 5: 99.33\n",
            "Class 6: 98.85\n",
            "Class 7: 99.12\n",
            "Class 8: 99.38\n",
            "Class 9: 98.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6vq9Nr3EG9oS"
      }
    }
  ]
}