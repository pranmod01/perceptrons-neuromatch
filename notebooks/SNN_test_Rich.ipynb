{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aec057e",
   "metadata": {},
   "source": [
    "# SNN Playground\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f124e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Version: 3.9.18 (main, Sep 11 2023, 13:30:38) [MSC v.1916 64 bit (AMD64)]\n",
      "PyTorch version 2.3.1+cu118\n",
      "Numpy version 1.26.4\n",
      "env path:  c:\\Users\\richa\\OneDrive\\Dugree\\Project\\cuda\\Scripts\\python.exe\n",
      "Using device:  cuda\n",
      "       --> 0 : NVIDIA GeForce RTX 2070\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import snntorch as snn\n",
    "from snntorch import spikeplot as split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Module\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rsatoolbox as rsa\n",
    "from rsatoolbox.inference import evaluate as eval\n",
    "from rsatoolbox.inference.bootstrap import (bootstrap_sample,\n",
    "                                            bootstrap_sample_pattern,\n",
    "                                            bootstrap_sample_rdm)\n",
    "from rsatoolbox.util.inference_util import all_tests, get_errorbars\n",
    "from rsatoolbox.util.rdm_utils import batch_to_vectors\n",
    "from rsatoolbox.util.inference_util import all_tests, get_errorbars\n",
    "from rsatoolbox.util.rdm_utils import batch_to_vectors\n",
    "\n",
    "print('System Version:', sys.version)\n",
    "print('PyTorch version', torch.__version__)\n",
    "print('Numpy version', np.__version__)\n",
    "print(\"env path: \", sys.executable) \n",
    "\n",
    "#[+] check to see if gpu is available, else use cpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('Using device: ',device)\n",
    "for i in range(torch.cuda.device_count()): print('       -->',i,':', torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34edb18a",
   "metadata": {},
   "source": [
    "## DataLoading MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd2a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 128\n",
    "data_path= r'./data'\n",
    "dtype= torch.float\n",
    "\n",
    "# Create the transoform for MNIST dataset to make sure its 28x28, grayscale, a tensor, and vals normalized to fall between 0 and 1\n",
    "transform= transforms.Compose([\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0,), (1,)),])\n",
    "\n",
    "# Automatically downloads and splits the MNIST dataset\n",
    "mnist_train = datasets.MNIST(data_path, train= True , download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(data_path, train= False, download=True, transform=transform)\n",
    "\n",
    "#create DataLoaders\n",
    "train_loader= DataLoader(mnist_train , batch_size= batch_size, shuffle=True, drop_last=True)\n",
    "test_loader= DataLoader(mnist_test , batch_size= batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeb1eed",
   "metadata": {},
   "source": [
    "# Construct a Fully Connected SNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf1909b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of inputs should match number of pixels in the MNIST img\n",
    "num_inputs= 28*28  #= 784\n",
    "\n",
    "# Hidden layer is however big you want as long as it fits in your GPU\n",
    "num_hidden= 1000\n",
    "\n",
    "# One output neuron for each of the 10 MNIST digits\n",
    "num_outputs= 10\n",
    "\n",
    "# 25 time steps is a quick simulation by default, reduce to 5 to match the layers of the CNN \n",
    "num_steps= 5\n",
    "\n",
    "# Rate of decay\n",
    "beta= 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4072903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Snn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers before defining the forward function\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # init hidden states at t=0, mem is membrane potential\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        \n",
    "        # [+] Record the hidden layer\n",
    "        spk1_rec = []\n",
    "        mem1_rec = []\n",
    "\n",
    "        # Record the final layer\n",
    "        spk2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            # x.shape: torch.Size([128, 784]) -> 128=batch_size, 784= 28x28 img; x is a batch of 128 images\n",
    "\n",
    "            # cur1 , spk1, mem1 shape:  torch.Size([128, 1000]) torch.Size([128, 1000]) torch.Size([128, 1000])\n",
    "            cur1 = self.fc1(x)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "            \n",
    "            # cur2 , spk2, mem2 shape:  torch.Size([128, 10]) torch.Size([128, 10]) torch.Size([128, 10])\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            \n",
    "            # [+] store hidden layer in list\n",
    "            spk1_rec.append(spk1)\n",
    "            mem1_rec.append(mem1)\n",
    "\n",
    "            # stor final layer in list\n",
    "            spk2_rec.append(spk2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        # rec stack sizes:  torch.Size([25, 128, 10]) torch.Size([25, 128, 10])\n",
    "        spk_stack, mem_stack= torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "        spk_stack_hid, mem_stack_hid= torch.stack(spk1_rec, dim=0), torch.stack(mem1_rec, dim=0)\n",
    "\n",
    "        # The network returns a tensor of spike recordings over time, and a tensor of membrane potential recordnigs over time\n",
    "        return spk_stack, mem_stack, spk_stack_hid, mem_stack_hid\n",
    "\n",
    "        \n",
    "# Load the network onto CUDA if available\n",
    "snn = Snn().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bff27f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648cf923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 \t Train Loss: 2.3025848865509033\n",
      "Iteration: 10 \t Train Loss: 1.2204513549804688\n",
      "Iteration: 20 \t Train Loss: 0.7334411144256592\n",
      "Iteration: 30 \t Train Loss: 0.44985485076904297\n",
      "Iteration: 40 \t Train Loss: 0.6332224607467651\n",
      "Iteration: 50 \t Train Loss: 0.6782404780387878\n",
      "Iteration: 60 \t Train Loss: 0.36670830845832825\n",
      "Iteration: 70 \t Train Loss: 0.47170495986938477\n",
      "Iteration: 80 \t Train Loss: 0.43472200632095337\n",
      "Iteration: 90 \t Train Loss: 0.5383827686309814\n",
      "   -->[x] no save\n",
      "Iteration: 100 \t Train Loss: 0.4722275137901306\n",
      "Iteration: 110 \t Train Loss: 0.3564048707485199\n",
      "Iteration: 120 \t Train Loss: 0.37622788548469543\n",
      "Iteration: 130 \t Train Loss: 0.46333035826683044\n",
      "Iteration: 140 \t Train Loss: 0.35184842348098755\n",
      "Iteration: 150 \t Train Loss: 0.5090261697769165\n",
      "Iteration: 160 \t Train Loss: 0.28077608346939087\n",
      "Iteration: 170 \t Train Loss: 0.37478503584861755\n",
      "Iteration: 180 \t Train Loss: 0.40501874685287476\n",
      "Iteration: 190 \t Train Loss: 0.2884025573730469\n",
      "Iteration: 200 \t Train Loss: 0.2926211953163147\n",
      "Iteration: 210 \t Train Loss: 0.27778294682502747\n",
      "Iteration: 220 \t Train Loss: 0.3264930844306946\n",
      "Iteration: 230 \t Train Loss: 0.3075494170188904\n",
      "Iteration: 240 \t Train Loss: 0.36407384276390076\n",
      "Iteration: 250 \t Train Loss: 0.38303035497665405\n",
      "Iteration: 260 \t Train Loss: 0.3885616958141327\n",
      "Iteration: 270 \t Train Loss: 0.30096501111984253\n",
      "Iteration: 280 \t Train Loss: 0.19907423853874207\n",
      "Iteration: 290 \t Train Loss: 0.26915737986564636\n",
      "Iteration: 300 \t Train Loss: 0.25588107109069824\n",
      "Iteration: 310 \t Train Loss: 0.2660925090312958\n",
      "Iteration: 320 \t Train Loss: 0.220707505941391\n",
      "Iteration: 330 \t Train Loss: 0.15572573244571686\n",
      "Iteration: 340 \t Train Loss: 0.1820111721754074\n",
      "Iteration: 350 \t Train Loss: 0.2861744165420532\n",
      "Iteration: 360 \t Train Loss: 0.3284156918525696\n",
      "Iteration: 370 \t Train Loss: 0.2590732276439667\n",
      "Iteration: 380 \t Train Loss: 0.22648903727531433\n",
      "Iteration: 390 \t Train Loss: 0.2981998324394226\n",
      "Iteration: 400 \t Train Loss: 0.2543163597583771\n",
      "Iteration: 410 \t Train Loss: 0.2468632012605667\n",
      "Iteration: 420 \t Train Loss: 0.21361945569515228\n",
      "Iteration: 430 \t Train Loss: 0.28857171535491943\n",
      "Iteration: 440 \t Train Loss: 0.24224573373794556\n",
      "Iteration: 450 \t Train Loss: 0.21037611365318298\n",
      "Iteration: 460 \t Train Loss: 0.2959475517272949\n",
      "Iteration: 470 \t Train Loss: 0.222959503531456\n",
      "Iteration: 480 \t Train Loss: 0.3141575753688812\n",
      "Iteration: 490 \t Train Loss: 0.20546282827854156\n",
      "Iteration: 500 \t Train Loss: 0.15338201820850372\n",
      "Iteration: 510 \t Train Loss: 0.2674653232097626\n",
      "Iteration: 520 \t Train Loss: 0.2784136235713959\n",
      "Iteration: 530 \t Train Loss: 0.23050616681575775\n",
      "Iteration: 540 \t Train Loss: 0.24762722849845886\n",
      "Iteration: 550 \t Train Loss: 0.26042208075523376\n",
      "Iteration: 560 \t Train Loss: 0.21590673923492432\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(snn.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "\n",
    "# # 60000 data samples / 128 samples per batch = approx 468 iterations\n",
    "num_epochs = 2\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "cntLim= 100\n",
    "saveMdl= False\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop: each batch will have data which is the 128 samples, and each sample will have target labels (digits 0-9), we load all into cuda\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        #forward pass: we set our network to train mode, and pass the data into it\n",
    "        snn.train()\n",
    "        spk_rec, mem_rec, _, _ = snn(data.flatten(1))\n",
    "        #spk_rec and mem_rec sizes:  torch.Size([25, 128, 10]) \n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        loss_val += loss(spk_rec.sum(0), targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Print train/test loss/accuracy\n",
    "        if counter % 10 == 0:\n",
    "            print(f\"Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n",
    "        counter += 1\n",
    "\n",
    "        if counter == cntLim:\n",
    "            if(saveMdl):\n",
    "                mdlName= 'snn_mdl_ts'+str(num_steps)+'_epoch'+str(num_epochs)+'.pth'\n",
    "                torch.save(snn.state_dict(), mdlName)\n",
    "                print(' -->[+] model saved as', mdlName)\n",
    "            else: print('   -->[x] no save')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646a9481",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74bc40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_accuracy(model, dataloader):\n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    running_length = 0\n",
    "    running_accuracy = 0\n",
    "\n",
    "    for data, targets in iter(dataloader):\n",
    "      # data shape:  torch.Size([128, 1, 28, 28])\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      # flat data shape:  torch.Size([128, 784]) -> a batch of 28x28 imsg is flattened to a batch of 1x784 along dim 1\n",
    "      data= data.flatten(1)\n",
    "\n",
    "      # spk_rec, mem_rec = model(data)\n",
    "      spk_rec, mem_rec, spk_stack_hid, mem_stack_hid = model(data)\n",
    "      \n",
    "      spike_count = spk_rec.sum(0)\n",
    "      _, max_spike = spike_count.max(1)\n",
    "\n",
    "      # correct classes for one batch\n",
    "      num_correct = (max_spike == targets).sum()\n",
    "\n",
    "      # total accuracy\n",
    "      running_length += len(targets)\n",
    "      running_accuracy += num_correct\n",
    "    \n",
    "    accuracy = (running_accuracy / running_length)\n",
    "\n",
    "    return accuracy.item(), spk_rec, mem_rec, spk_stack_hid, mem_stack_hid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ccc38e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spk_rec:  torch.Size([5, 128, 10]) \n",
      " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') \n",
      "\n",
      "mem_rec:  torch.Size([5, 128, 10]) \n",
      " tensor([-0.5911,  0.7088, -0.3737,  0.1831,  0.0917, -0.3519, -0.1989,  0.1886,\n",
      "         0.9672,  0.3873], device='cuda:0') \n",
      "\n",
      "spk_stack_hid:  torch.Size([5, 128, 1000]) \n",
      " tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0') \n",
      "\n",
      "mem_stack_hid:  torch.Size([5, 128, 1000]) \n",
      " tensor([-2.7618e-01,  3.4331e-01, -3.1849e-01,  1.1671e+00, -3.5235e-01,\n",
      "        -2.3414e-01,  5.6479e-01, -5.2750e-01,  2.0835e-01,  1.1259e-01,\n",
      "         2.1514e-01, -3.6477e-02, -6.3716e-01,  1.0462e+00,  5.7043e-01,\n",
      "        -9.8725e-02,  6.3130e-01,  1.4149e-01,  2.5502e-01,  1.1866e-01,\n",
      "         1.0385e+00, -5.7284e-01,  9.1748e-02, -4.7995e-01, -3.5474e-01,\n",
      "         2.8886e-02,  1.2453e-01,  6.3509e-01, -1.8771e-01, -1.1308e+00,\n",
      "         8.6972e-01,  4.7583e-01, -2.2901e-01, -1.1666e-01,  9.0506e-01,\n",
      "         3.1612e-01,  4.8314e-01, -1.2554e+00, -6.4402e-01, -4.1502e-02,\n",
      "         5.6749e-01, -7.0265e-02, -4.5664e-02, -4.5246e-01,  6.5567e-02,\n",
      "        -4.7079e-01, -1.2168e+00,  5.0215e-01,  6.9754e-01, -3.1173e-01,\n",
      "         7.9973e-01,  2.5515e-01, -1.5093e+00,  7.2500e-01,  4.1105e-01,\n",
      "         1.1959e-02, -4.0440e-02,  2.6211e-01, -1.3133e+00,  1.8425e-01,\n",
      "         7.2744e-01, -1.5334e-02,  1.5698e+00,  1.2336e-01,  5.0415e-01,\n",
      "        -1.4742e+00,  9.7093e-02, -1.7197e+00,  1.6175e-01, -1.2890e+00,\n",
      "        -1.2997e+00,  3.2071e-01, -8.6839e-01, -5.4370e-01,  3.1022e-01,\n",
      "        -6.4881e-01, -1.8325e-01,  1.2670e-01,  2.1139e-01, -6.3624e-01,\n",
      "        -7.1390e-01,  2.0537e-01,  3.2117e-01,  8.9745e-01,  1.8437e-01,\n",
      "        -5.5869e-01, -3.6127e-01, -1.5552e+00, -4.9486e-01,  3.3231e-01,\n",
      "         6.1338e-01, -1.5337e-01,  3.0724e-01, -5.6963e-02,  7.0088e-01,\n",
      "        -2.5199e-01,  1.8284e-01,  9.9284e-01,  4.5501e-01,  1.2212e+00,\n",
      "        -4.3212e-01,  8.4094e-01,  1.1793e-02, -6.9644e-01, -4.8993e-01,\n",
      "         2.9456e-01,  9.6108e-02,  4.1729e-01, -4.2878e-01, -4.2388e-01,\n",
      "         3.3107e-01, -3.2456e-01,  2.1154e-01,  6.6449e-01,  1.8465e-01,\n",
      "        -3.1140e-01,  1.5061e-02,  1.6121e-01,  1.1891e+00, -7.4990e-01,\n",
      "         4.4473e-01,  1.0123e-01,  1.2412e+00,  8.4417e-02,  1.3497e-01,\n",
      "        -1.8857e-01,  6.1002e-01,  1.2442e+00,  3.8417e-01, -3.7386e-01,\n",
      "         8.1223e-01,  1.1113e+00,  3.9384e-02,  9.1385e-01, -3.5636e-01,\n",
      "        -4.7637e-01,  1.2864e-01, -9.8834e-01, -2.3246e-01, -7.6843e-01,\n",
      "         6.2015e-01,  4.2993e-01, -5.2651e-01, -1.8748e+00,  8.1447e-01,\n",
      "         8.3035e-01,  5.6714e-01,  1.2682e+00,  9.5581e-01,  4.7212e-01,\n",
      "         4.2369e-01, -2.8761e-01,  5.6663e-01, -1.0617e+00,  4.6255e-01,\n",
      "        -1.4339e-02, -2.6877e-01,  3.9908e-02, -2.1844e-01, -1.8714e+00,\n",
      "         1.4584e+00, -2.4139e-02, -9.8973e-01,  7.0712e-01,  6.2648e-01,\n",
      "        -1.0015e-01,  1.6105e+00,  4.7854e-01,  4.9632e-01, -1.3849e+00,\n",
      "        -5.2848e-01, -1.9056e-01, -3.8618e-01, -2.1787e-01,  9.7802e-01,\n",
      "         8.9993e-01,  2.1883e-01,  6.7975e-02, -4.0159e-01,  6.3437e-01,\n",
      "         5.6657e-01,  8.5110e-02,  5.3966e-01,  3.2859e-01, -2.6926e-01,\n",
      "         1.5964e-01,  4.0312e-01, -1.4184e-01, -7.1052e-01, -9.0567e-02,\n",
      "         1.0164e-01,  1.5674e-02,  1.5168e+00,  1.4305e-01,  3.4229e-01,\n",
      "        -3.2003e-01, -2.9228e-01, -6.0272e-01,  2.9153e-01,  5.2342e-01,\n",
      "         4.0234e-02, -5.7371e-01, -1.0461e+00, -1.0457e+00, -1.2959e+00,\n",
      "         7.2629e-02,  3.0333e-01,  2.0434e-01, -9.8772e-01,  6.9547e-01,\n",
      "         5.3105e-01,  7.5285e-01, -4.3916e-02,  8.8267e-01, -3.2935e-01,\n",
      "         4.3103e-01, -9.6520e-02,  5.4612e-02,  7.4339e-02,  2.1638e-01,\n",
      "         1.2326e+00,  4.6593e-01,  3.3441e-01, -4.6083e-02,  6.4786e-01,\n",
      "        -1.0314e+00,  9.1622e-01,  6.3425e-01,  1.1795e+00,  2.4931e-01,\n",
      "         1.1633e+00,  3.6435e-01, -1.0517e+00, -2.3981e-01, -8.3723e-01,\n",
      "         1.4259e+00,  6.6984e-01,  1.0005e+00,  6.0671e-01, -1.1501e+00,\n",
      "         2.9065e-01,  1.7032e-01,  1.5362e-01,  4.1470e-01,  4.1407e-01,\n",
      "         6.6146e-01,  4.5881e-01,  2.3162e-01,  8.5998e-02,  4.4861e-01,\n",
      "        -7.6932e-01,  1.7850e-01,  7.5693e-01,  1.8817e-01,  3.0131e-01,\n",
      "         7.1932e-01,  9.1431e-01, -1.0662e-02, -1.9935e-02,  4.8235e-01,\n",
      "         4.4001e-01,  2.6534e-01,  6.1326e-01, -5.8338e-01,  7.2946e-01,\n",
      "         5.3107e-01, -1.4250e-01,  6.1036e-01, -4.3669e-02, -7.8182e-02,\n",
      "        -3.8025e-02,  1.1217e+00, -4.3235e-01, -1.5547e+00, -1.8711e+00,\n",
      "         2.4747e-01,  1.4093e-01,  8.4461e-01,  2.3713e-01,  8.7425e-01,\n",
      "         2.7406e-01,  1.7606e-01,  5.0092e-02, -5.9795e-01, -5.6824e-01,\n",
      "        -4.6589e-01,  8.7363e-01, -6.0863e-01,  5.0303e-02,  7.0916e-02,\n",
      "         8.8205e-01,  7.1703e-01, -1.1777e-01,  7.4815e-02,  2.4748e-01,\n",
      "        -2.6399e-01,  2.1345e-01,  4.0730e-01, -3.7541e-01,  7.0845e-01,\n",
      "         4.4511e-01, -1.5610e+00,  6.8751e-01,  9.3674e-01, -3.5040e-02,\n",
      "        -7.0428e-03,  3.2964e-01, -1.8097e+00, -9.1282e-01,  3.4102e-01,\n",
      "         3.5504e-01, -2.7364e-01,  7.0641e-01,  5.9511e-01, -1.3885e+00,\n",
      "         8.2021e-01, -3.6807e-02, -7.5376e-01, -2.6234e-01, -2.1415e-01,\n",
      "         4.2821e-01,  4.4467e-01,  1.2775e-01, -2.3368e-01, -4.0473e-01,\n",
      "         5.5543e-02, -1.4463e-01, -4.1039e-01,  5.2711e-01, -1.3851e-02,\n",
      "         1.5202e-01,  9.5704e-02,  1.2278e+00,  8.0464e-02,  3.8369e-01,\n",
      "        -7.6322e-01,  1.4180e-01,  7.9436e-01,  2.9201e-01,  2.0438e-02,\n",
      "        -2.8414e-01,  6.6102e-01, -1.6458e+00, -2.9381e-01, -7.4018e-01,\n",
      "         1.4645e+00, -2.0698e-01,  3.2887e-01,  3.0175e-01, -3.3059e-02,\n",
      "         1.2814e+00, -3.9905e-02,  1.0661e+00,  1.3926e+00, -4.3377e-01,\n",
      "        -9.0116e-02, -8.3411e-01,  4.0477e-02, -2.4617e-01,  5.6173e-01,\n",
      "        -3.6586e-01,  5.2171e-02,  7.5789e-01,  4.8405e-01,  6.2849e-02,\n",
      "        -6.5418e-01,  7.4833e-02, -5.1684e-01,  2.8003e-01,  1.2757e+00,\n",
      "        -1.4144e-01, -6.9832e-01, -6.4905e-01,  5.8882e-01, -9.2853e-01,\n",
      "         3.2835e-01,  3.0097e-01,  3.0680e-01, -5.2305e-01,  1.5473e-01,\n",
      "         3.2822e-01, -9.3337e-01,  4.1071e-01, -1.3338e-01, -7.1265e-02,\n",
      "        -7.6348e-01, -4.1637e-01, -1.6580e-01, -9.1528e-01, -6.9297e-01,\n",
      "        -3.8872e-01,  3.2991e-01,  3.7142e-01,  1.1610e+00,  7.7507e-01,\n",
      "         6.3207e-01, -6.3080e-01, -9.6947e-03,  9.7962e-02, -3.6951e-01,\n",
      "         3.9498e-01, -1.1015e-01,  4.6553e-01, -4.9428e-01,  2.7592e-01,\n",
      "         4.0767e-01, -1.3461e+00, -1.0680e+00, -8.4482e-01,  1.0717e+00,\n",
      "        -6.9456e-02,  9.0267e-01,  3.7072e-01,  3.7539e-01, -7.1737e-01,\n",
      "         7.2909e-01,  7.8630e-01, -4.0915e-01,  4.9357e-01,  6.3488e-01,\n",
      "         8.2665e-02,  1.1605e+00,  8.3149e-02,  3.9090e-01,  6.7439e-01,\n",
      "         3.3302e-01, -5.6542e-01, -6.9822e-01,  1.0387e+00,  3.7434e-01,\n",
      "         5.3281e-01, -5.4964e-01,  2.3848e-01, -1.7561e-01,  2.3561e-01,\n",
      "        -4.2649e-01, -8.6831e-01, -9.1211e-01,  6.2192e-01,  5.2231e-01,\n",
      "         1.2106e+00,  7.3952e-01,  6.3455e-01, -4.6081e-02, -7.1544e-02,\n",
      "        -1.2349e+00,  7.6649e-01,  1.3691e-01, -3.3401e-01, -4.5406e-01,\n",
      "        -1.4598e+00,  4.1830e-01, -9.1956e-01,  5.5883e-01,  9.4780e-03,\n",
      "         1.3130e-01, -3.8568e-01,  1.8284e+00,  1.1297e-01,  4.4735e-01,\n",
      "        -5.5423e-02,  8.6933e-01,  2.1035e-01, -7.7577e-01, -2.7983e-01,\n",
      "         1.2592e+00,  5.8023e-01, -1.8685e-01, -5.6669e-01,  2.0048e-01,\n",
      "        -2.1519e-01, -5.1257e-01,  5.7826e-02,  3.1318e-01, -3.3336e-01,\n",
      "         5.2937e-01, -1.0829e-02, -4.4384e-01, -7.7658e-01,  1.4471e-01,\n",
      "         1.6420e-03,  2.1874e-01, -9.9625e-01,  1.2507e-01,  6.0609e-01,\n",
      "        -1.7617e+00, -1.6171e-01, -1.8084e-01, -1.9864e-01,  2.1607e-01,\n",
      "         1.3069e-01,  1.4332e-01, -2.2738e-01,  5.7046e-02,  3.8150e-01,\n",
      "        -1.9357e-01,  3.5385e-01,  2.0261e-01,  7.7996e-01,  6.2392e-01,\n",
      "        -1.9298e-02, -8.0793e-01, -5.8533e-01, -9.3398e-01,  2.1319e-01,\n",
      "        -2.5754e-01,  2.5464e-01,  4.9493e-01,  2.5232e-01,  7.3959e-01,\n",
      "         2.3054e-02,  8.9328e-02, -1.2510e+00,  4.8951e-01,  2.5494e-01,\n",
      "        -7.0861e-01, -4.1494e-01, -4.2191e-01, -2.5958e-01, -2.8613e-01,\n",
      "        -4.1172e-01,  1.9712e-01,  1.5273e-01, -4.2220e-02, -3.6015e-01,\n",
      "         1.6331e-01,  5.6315e-02,  1.2425e+00,  5.6599e-01, -8.3366e-01,\n",
      "         1.1513e+00,  7.8200e-02,  4.3408e-01, -4.6976e-01,  1.3969e-01,\n",
      "         1.1184e+00,  4.5299e-01,  2.4198e-01, -2.9192e-01, -1.1549e+00,\n",
      "        -5.9039e-01,  1.0485e-01, -7.6599e-01,  5.8403e-01,  4.9181e-01,\n",
      "         9.2758e-02, -8.3242e-02,  3.7718e-01, -2.7896e-01,  1.1158e-01,\n",
      "         5.7742e-01, -3.2445e-01,  4.3751e-01, -1.0641e-01,  2.2386e-01,\n",
      "         1.4557e-01,  3.9004e-02,  4.7411e-02,  4.1659e-01, -1.3215e+00,\n",
      "         2.9772e-01,  1.0226e-01,  3.7380e-01,  3.3692e-01, -1.7649e+00,\n",
      "        -1.2245e+00, -1.0479e+00, -9.0923e-01,  1.2797e-01,  4.9145e-01,\n",
      "        -1.3033e-01,  2.6101e-01, -1.6848e-01,  6.6597e-01, -4.1631e-01,\n",
      "         4.7940e-01,  7.8502e-01, -6.2229e-02, -1.2502e+00, -1.5148e-01,\n",
      "         6.1670e-03, -5.5517e-01,  9.1533e-02, -9.1989e-01, -2.9195e-02,\n",
      "         5.5461e-01,  7.8600e-02,  4.7225e-01,  3.2371e-01,  4.6291e-01,\n",
      "        -2.1606e-01, -5.0956e-01,  9.0450e-01,  8.6892e-01,  2.6925e-01,\n",
      "        -4.3140e-02, -2.8789e-01,  5.6048e-01, -6.1840e-01, -7.1129e-02,\n",
      "         8.9498e-02,  5.8248e-01,  1.5883e+00, -1.1390e+00, -2.0678e-01,\n",
      "         8.9252e-01,  9.0340e-01, -1.3058e-01,  1.2313e+00,  8.0969e-01,\n",
      "         1.8627e-01,  9.9569e-01, -3.8475e-01, -1.5794e-01,  7.3212e-02,\n",
      "         4.5496e-01, -1.2837e-02, -4.9187e-01,  1.5466e-01, -8.2652e-01,\n",
      "         4.0426e-01, -7.8608e-02,  4.4807e-01, -3.1333e-01,  5.9593e-01,\n",
      "        -1.2594e+00,  1.2874e+00,  3.2018e-01,  5.0013e-01, -1.1001e-03,\n",
      "         1.1931e-01,  1.1791e+00,  9.9503e-01,  7.3966e-01, -7.0842e-01,\n",
      "        -3.4293e-02,  6.9978e-01,  8.2590e-01,  1.0464e+00,  8.5316e-02,\n",
      "        -7.9271e-01, -1.6202e-01,  7.4905e-01, -6.3490e-02, -1.9118e-01,\n",
      "         9.5691e-01,  1.3943e+00,  6.8186e-02,  9.3228e-01, -7.2009e-02,\n",
      "         5.5832e-01, -4.2383e-01, -2.6669e-01, -4.0851e-02, -6.3287e-01,\n",
      "         1.1376e-01,  9.3952e-01,  4.2715e-01,  3.2908e-01,  6.5800e-02,\n",
      "         3.1072e-02,  8.0609e-02,  6.4958e-01,  4.7023e-01,  2.8559e-01,\n",
      "         3.3574e-01,  1.1749e+00,  6.6129e-01, -1.0412e+00, -6.6933e-02,\n",
      "        -1.1343e+00,  3.1554e-01, -3.3516e-01, -4.3009e-02, -1.8439e-01,\n",
      "         2.0185e-01, -1.0135e+00,  1.6165e-01,  2.5786e-01,  1.6823e+00,\n",
      "        -3.9857e-01,  1.0374e+00,  6.1541e-01,  3.5404e-02,  5.1843e-01,\n",
      "        -2.8136e-02, -1.1883e-01, -6.4597e-01,  4.0395e-01, -3.5025e-01,\n",
      "         7.9059e-02,  4.4378e-01,  1.4395e-01,  1.0625e+00,  7.8161e-02,\n",
      "         1.0764e+00, -1.9454e-01,  8.9599e-01,  1.2355e+00,  3.6546e-01,\n",
      "         1.1725e-01, -1.6632e-01, -1.3350e+00, -1.0014e+00,  1.3126e-02,\n",
      "         5.2769e-01,  1.3227e-01,  1.4740e+00,  1.3318e+00,  4.0325e-01,\n",
      "         7.7476e-01,  5.7327e-01, -1.9892e-01, -1.5898e-01,  1.3015e+00,\n",
      "         2.0130e-01,  3.8301e-01,  8.4313e-01, -4.3251e-01,  2.1912e+00,\n",
      "         6.1840e-01, -2.1778e-02,  1.2378e+00,  1.1828e+00, -2.4558e-01,\n",
      "         5.3238e-01, -5.6911e-01, -2.5278e-02,  1.2628e+00,  1.0526e+00,\n",
      "         9.8539e-01, -2.9644e-01, -7.2917e-01, -3.5739e-01, -9.9602e-01,\n",
      "        -7.3153e-01, -2.6383e-01, -5.6908e-01, -4.6923e-01,  8.2424e-01,\n",
      "        -1.4560e+00,  3.3569e-01,  8.6523e-01, -2.6203e-02, -1.1217e+00,\n",
      "        -2.4046e-01,  2.7040e-01, -1.1011e-01,  4.2908e-01, -1.0090e+00,\n",
      "        -1.0614e-01,  2.0070e+00, -5.3927e-02, -2.8190e-02, -7.7357e-01,\n",
      "        -1.2982e-01,  8.3527e-01,  6.2953e-02, -3.4446e-02,  7.3488e-01,\n",
      "        -4.8259e-01,  2.6901e-02, -2.8240e-01, -1.0224e-01,  1.2276e+00,\n",
      "        -1.7270e-01, -1.1918e+00, -2.5591e-01,  4.0062e-01,  1.2911e-01,\n",
      "        -3.1921e-01,  1.0018e+00,  2.2836e-01,  8.5089e-01,  5.4343e-01,\n",
      "         2.4093e-01,  1.3415e+00, -3.9453e-01,  1.1867e+00, -1.1243e-01,\n",
      "        -2.1108e-01, -8.3488e-01, -8.1090e-01,  1.9699e-01, -1.1070e+00,\n",
      "         2.3003e-01,  2.8904e-01,  1.3106e-01, -2.3627e-01,  1.4766e-01,\n",
      "         1.6998e-01, -8.9619e-02,  3.2784e-01,  4.4663e-01, -1.0406e+00,\n",
      "         6.4844e-01, -1.8246e-01, -6.4127e-01,  6.0723e-01,  4.0614e-01,\n",
      "         8.4373e-01, -9.3613e-02,  1.1828e+00,  3.5298e-01,  6.0824e-01,\n",
      "        -4.6138e-01,  4.4400e-01, -3.8574e-01,  2.6705e-01, -4.5452e-01,\n",
      "         7.4130e-02,  1.9296e-01,  6.4167e-01, -9.7148e-01,  1.1203e-01,\n",
      "         3.8729e-02, -7.3788e-02,  3.9856e-01,  1.0722e+00,  6.6145e-01,\n",
      "        -5.7495e-02,  4.3184e-01, -1.4359e-01,  6.5455e-02, -1.2725e+00,\n",
      "         4.3279e-01, -6.3037e-01, -3.6855e-01,  2.7514e-03,  1.5821e-01,\n",
      "         3.5605e-01,  1.0651e+00, -5.7146e-01,  3.7190e-01,  1.5361e-01,\n",
      "         1.5167e+00, -5.7305e-02,  1.1845e-01,  8.5376e-01, -1.0932e+00,\n",
      "         7.0289e-01, -1.2328e-01,  1.0775e-01,  2.3497e-02, -1.6248e+00,\n",
      "         2.5431e-01, -2.6210e-01,  3.9954e-01,  3.0247e-02,  4.5017e-02,\n",
      "        -2.1470e-01,  7.7404e-01, -7.0070e-01, -1.7843e-01, -3.3839e-01,\n",
      "         1.0316e-01,  9.0039e-01,  4.9710e-01,  1.2759e+00, -4.1912e-01,\n",
      "         1.5481e-01,  4.8409e-01,  3.3154e-01,  4.8958e-01, -3.5891e-01,\n",
      "         2.9917e-01,  1.2569e-01,  5.0270e-01, -1.6415e-01, -2.9935e-01,\n",
      "         7.8844e-02,  6.0301e-01,  6.1321e-01,  1.7713e-01,  7.9100e-01,\n",
      "         6.1308e-01, -1.8500e-01,  8.5804e-01, -6.3701e-01, -5.4286e-02,\n",
      "        -3.6725e-02, -6.3213e-01,  5.1567e-01,  5.8512e-01,  6.7620e-01,\n",
      "        -4.2518e-01,  5.1308e-02,  2.4656e-01, -9.6366e-05,  6.2208e-01,\n",
      "        -1.7573e-02,  4.5609e-01, -2.7465e-01,  2.4197e-01, -8.8319e-01,\n",
      "         6.2707e-01,  3.8212e-01,  1.9589e-02, -8.7400e-01,  9.1022e-01,\n",
      "         6.2547e-01,  8.2746e-01,  3.5013e-02, -1.2137e+00,  5.9975e-01,\n",
      "        -7.4010e-01, -6.5533e-01,  5.0642e-02,  1.2696e-02,  7.8329e-01,\n",
      "        -2.6570e-01, -2.0119e-01,  8.4777e-01,  3.9670e-01, -5.1537e-01,\n",
      "         4.6642e-01, -1.1581e+00, -3.0965e-01, -2.5778e-01, -5.0358e-01,\n",
      "        -4.0049e-01, -7.6181e-02, -5.2132e-01, -1.3144e+00,  1.0995e+00,\n",
      "        -6.0619e-01, -5.0215e-01,  1.9501e-01,  5.2513e-01,  7.2307e-01,\n",
      "        -8.0243e-01,  8.3227e-01,  4.2651e-01,  9.2466e-02, -1.5948e-01,\n",
      "         9.9339e-01, -6.7317e-01,  1.3522e+00, -1.8637e-01,  6.8579e-01,\n",
      "        -1.0978e+00,  7.7382e-01,  7.9688e-01,  9.3129e-01,  1.0637e-01,\n",
      "         1.3636e+00, -2.3626e-01,  3.8373e-01,  1.3291e+00, -8.7845e-02,\n",
      "        -1.1801e-01,  9.4758e-01, -3.8594e-01,  7.7831e-01,  2.6385e-01,\n",
      "        -1.0543e-01,  6.4362e-01, -9.2130e-01,  4.0524e-01, -2.6636e-01,\n",
      "        -1.0307e+00, -5.5501e-01,  6.2104e-01, -5.3676e-02, -5.7329e-02,\n",
      "         1.3318e-01,  3.0333e-01, -1.2876e+00,  1.1845e+00,  2.2168e-01,\n",
      "         6.0295e-01, -6.8044e-01, -1.6106e-02,  7.6809e-01,  3.3099e-01,\n",
      "        -7.3208e-01, -1.2179e-01, -8.5948e-02,  9.8883e-01, -7.7779e-01,\n",
      "         1.3899e+00, -1.7396e-01, -9.4881e-01,  1.1932e-01,  6.2572e-01,\n",
      "        -9.3540e-01, -2.5436e-01, -2.5382e-01,  1.6733e-02,  7.3365e-01,\n",
      "        -2.5791e-01, -5.1500e-01,  1.1719e+00,  3.9949e-01, -4.1581e-01,\n",
      "        -6.9569e-01,  5.7070e-02,  1.9101e-02, -1.2497e+00, -3.8283e-01],\n",
      "       device='cuda:0') \n",
      "\n",
      "Accuracy:  0.962740421295166\n"
     ]
    }
   ],
   "source": [
    "# Sanity\n",
    "accuracy, spk_rec, mem_rec, spk_stack_hid, mem_stack_hid= measure_accuracy(snn, test_loader)\n",
    "\n",
    "# dimensions: [timesteps x batchSize x params]\n",
    "print('spk_rec: ', spk_rec.shape,'\\n', spk_rec[0][0],'\\n')\n",
    "print('mem_rec: ', mem_rec.shape,'\\n',mem_rec[0][0],'\\n')\n",
    "print('spk_stack_hid: ', spk_stack_hid.shape,'\\n', spk_stack_hid[0][0],'\\n')\n",
    "print('mem_stack_hid: ', mem_stack_hid.shape,'\\n',mem_stack_hid[0][0],'\\n')\n",
    "print( 'Accuracy: ', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a91099",
   "metadata": {},
   "source": [
    "## RSA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59de4546",
   "metadata": {},
   "source": [
    "Create the dataset for spikes and membrane potential of the hidden layer to be used for RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c97e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'timeStep_1': rsatoolbox.data.Dataset(\n",
      "measurements = \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "descriptors = \n",
      "{'layer': 'timeStep_1'}\n",
      "obs_descriptors = \n",
      "{'image': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])}\n",
      "channel_descriptors = \n",
      "{'channel': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
      "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
      "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
      "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
      "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
      "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
      "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
      "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
      "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
      "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
      "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
      "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
      "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
      "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
      "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
      "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
      "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
      "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
      "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
      "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
      "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
      "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
      "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
      "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
      "       871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
      "       884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
      "       897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
      "       910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n",
      "       923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
      "       936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n",
      "       949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
      "       962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n",
      "       975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n",
      "       988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])}\n",
      ", 'timeStep_2': rsatoolbox.data.Dataset(\n",
      "measurements = \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 1. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]]\n",
      "descriptors = \n",
      "{'layer': 'timeStep_2'}\n",
      "obs_descriptors = \n",
      "{'image': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])}\n",
      "channel_descriptors = \n",
      "{'channel': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
      "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
      "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
      "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
      "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
      "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
      "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
      "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
      "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
      "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
      "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
      "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
      "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
      "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
      "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
      "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
      "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
      "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
      "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
      "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
      "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
      "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
      "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
      "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
      "       871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
      "       884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
      "       897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
      "       910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n",
      "       923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
      "       936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n",
      "       949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
      "       962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n",
      "       975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n",
      "       988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])}\n",
      ", 'timeStep_3': rsatoolbox.data.Dataset(\n",
      "measurements = \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]]\n",
      "descriptors = \n",
      "{'layer': 'timeStep_3'}\n",
      "obs_descriptors = \n",
      "{'image': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])}\n",
      "channel_descriptors = \n",
      "{'channel': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
      "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
      "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
      "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
      "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
      "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
      "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
      "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
      "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
      "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
      "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
      "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
      "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
      "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
      "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
      "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
      "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
      "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
      "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
      "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
      "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
      "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
      "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
      "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
      "       871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
      "       884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
      "       897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
      "       910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n",
      "       923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
      "       936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n",
      "       949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
      "       962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n",
      "       975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n",
      "       988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])}\n",
      ", 'timeStep_4': rsatoolbox.data.Dataset(\n",
      "measurements = \n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1. ... 1. 0. 0.]\n",
      " [0. 1. 0. ... 0. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 1.]]\n",
      "descriptors = \n",
      "{'layer': 'timeStep_4'}\n",
      "obs_descriptors = \n",
      "{'image': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])}\n",
      "channel_descriptors = \n",
      "{'channel': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
      "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
      "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
      "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
      "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
      "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
      "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
      "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
      "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
      "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
      "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
      "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
      "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
      "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
      "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
      "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
      "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
      "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
      "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
      "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
      "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
      "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
      "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
      "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
      "       871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
      "       884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
      "       897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
      "       910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n",
      "       923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
      "       936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n",
      "       949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
      "       962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n",
      "       975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n",
      "       988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])}\n",
      ", 'timeStep_5': rsatoolbox.data.Dataset(\n",
      "measurements = \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 1. 1. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "descriptors = \n",
      "{'layer': 'timeStep_5'}\n",
      "obs_descriptors = \n",
      "{'image': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])}\n",
      "channel_descriptors = \n",
      "{'channel': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
      "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
      "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
      "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
      "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
      "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
      "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
      "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
      "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
      "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
      "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
      "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
      "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
      "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
      "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
      "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
      "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
      "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
      "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
      "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
      "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
      "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
      "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
      "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
      "       871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
      "       884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
      "       897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
      "       910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n",
      "       923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
      "       936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n",
      "       949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
      "       962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n",
      "       975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n",
      "       988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])}\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'timeStep_1': rsatoolbox.data.Dataset(\n",
      "measurements = \n",
      "[[-2.76179552e-01  3.43310207e-01 -3.18490326e-01 ...  1.91007704e-02\n",
      "  -1.24968743e+00 -3.82825524e-01]\n",
      " [-3.71484309e-01  2.12608129e-01 -7.46348143e-01 ... -9.87494439e-02\n",
      "  -9.66134787e-01 -4.15808201e-01]\n",
      " [-1.10813454e-01  2.75398374e-01 -4.90519375e-01 ...  1.20407425e-01\n",
      "   6.57070279e-02  1.49583220e-01]\n",
      " ...\n",
      " [ 2.49605805e-01  7.95077562e-01  8.34316254e-01 ...  6.76045537e-01\n",
      "  -1.11828029e-01 -2.85933465e-01]\n",
      " [ 1.98518664e-01  8.34281087e-01 -2.07481578e-01 ...  2.39951283e-01\n",
      "   1.49201477e+00 -1.62875712e-01]\n",
      " [-7.71581978e-02  1.06483412e+00 -6.64889812e-05 ...  2.23709047e-02\n",
      "   6.81956410e-02  8.25374782e-01]]\n",
      "descriptors = \n",
      "{'layer': 'timeStep_1'}\n",
      "obs_descriptors = \n",
      "{'image': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])}\n",
      "channel_descriptors = \n",
      "{'channel': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
      "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
      "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
      "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
      "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
      "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
      "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
      "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
      "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
      "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
      "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
      "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
      "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
      "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
      "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
      "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
      "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
      "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
      "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
      "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
      "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
      "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
      "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
      "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
      "       871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
      "       884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
      "       897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
      "       910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n",
      "       923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
      "       936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n",
      "       949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
      "       962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n",
      "       975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n",
      "       988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])}\n",
      ", 'timeStep_2': rsatoolbox.data.Dataset(\n",
      "measurements = \n",
      "[[-5.3855014e-01  6.6945493e-01 -6.2105614e-01 ...  3.7246503e-02\n",
      "  -2.4368906e+00 -7.4650979e-01]\n",
      " [-7.2439444e-01  4.1458583e-01 -1.4553789e+00 ... -1.9256142e-01\n",
      "  -1.8839629e+00 -8.1082594e-01]\n",
      " [-2.1608624e-01  5.3702682e-01 -9.5651281e-01 ...  2.3479447e-01\n",
      "   1.2812871e-01  2.9168728e-01]\n",
      " ...\n",
      " [ 4.8673132e-01  1.5504012e+00  1.6269166e+00 ...  1.3182888e+00\n",
      "  -2.1806467e-01 -5.5757022e-01]\n",
      " [ 3.8711140e-01  1.6268481e+00 -4.0458906e-01 ...  4.6790498e-01\n",
      "   1.9094288e+00 -3.1760764e-01]\n",
      " [-1.5045848e-01  1.0764265e+00 -1.2965352e-04 ...  4.3623261e-02\n",
      "   1.3298151e-01  1.6094809e+00]]\n",
      "descriptors = \n",
      "{'layer': 'timeStep_2'}\n",
      "obs_descriptors = \n",
      "{'image': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])}\n",
      "channel_descriptors = \n",
      "{'channel': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
      "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
      "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
      "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
      "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
      "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
      "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
      "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
      "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
      "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
      "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
      "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
      "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
      "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
      "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
      "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
      "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
      "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
      "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
      "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
      "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
      "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
      "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
      "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
      "       871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
      "       884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
      "       897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
      "       910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n",
      "       923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
      "       936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n",
      "       949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
      "       962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n",
      "       975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n",
      "       988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])}\n",
      ", 'timeStep_3': rsatoolbox.data.Dataset(\n",
      "measurements = \n",
      "[[-7.8780216e-01  9.7929239e-01 -9.0849364e-01 ...  5.4484949e-02\n",
      "  -3.5647335e+00 -1.0920098e+00]\n",
      " [-1.0596590e+00  6.0646462e-01 -2.1289582e+00 ... -2.8168279e-01\n",
      "  -2.7558994e+00 -1.1860929e+00]\n",
      " [-3.1609538e-01  7.8557384e-01 -1.3992065e+00 ...  3.4346217e-01\n",
      "   1.8742931e-01  4.2668614e-01]\n",
      " ...\n",
      " [ 7.1200055e-01  1.2679586e+00  1.3798871e+00 ...  9.2841983e-01\n",
      "  -3.1898946e-01 -8.1562519e-01]\n",
      " [ 5.6627452e-01  1.3797867e+00 -5.9184116e-01 ...  6.8446100e-01\n",
      "   2.3059721e+00 -4.6460298e-01]\n",
      " [-2.2009376e-01  1.0874393e+00 -1.8965983e-04 ...  6.3813001e-02\n",
      "   1.9452807e-01  1.3543816e+00]]\n",
      "descriptors = \n",
      "{'layer': 'timeStep_3'}\n",
      "obs_descriptors = \n",
      "{'image': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])}\n",
      "channel_descriptors = \n",
      "{'channel': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
      "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
      "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
      "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
      "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
      "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
      "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
      "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
      "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
      "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
      "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
      "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
      "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
      "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
      "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
      "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
      "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
      "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
      "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
      "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
      "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
      "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
      "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
      "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
      "       871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
      "       884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
      "       897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
      "       910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n",
      "       923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
      "       936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n",
      "       949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
      "       962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n",
      "       975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n",
      "       988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])}\n",
      ", 'timeStep_4': rsatoolbox.data.Dataset(\n",
      "measurements = \n",
      "[[-1.0245916e+00  1.2736380e+00 -1.1815593e+00 ...  7.0861474e-02\n",
      "  -4.6361842e+00 -1.4202348e+00]\n",
      " [-1.3781604e+00  7.8874946e-01 -2.7688584e+00 ... -3.6634809e-01\n",
      "  -3.5842392e+00 -1.5425963e+00]\n",
      " [-4.1110408e-01  1.0216935e+00 -1.8197656e+00 ...  4.4669649e-01\n",
      "   2.4376486e-01  5.5493504e-01]\n",
      " ...\n",
      " [ 9.2600632e-01  9.9963820e-01  1.1452088e+00 ...  1.5580444e+00\n",
      "  -4.1486800e-01 -1.0607774e+00]\n",
      " [ 7.3647940e-01  1.1450784e+00 -7.6973069e-01 ...  8.9018917e-01\n",
      "   2.6826882e+00 -6.0424852e-01]\n",
      " [-2.8624725e-01  1.0979013e+00 -2.4666582e-04 ...  8.2993254e-02\n",
      "   2.5299731e-01  1.1120372e+00]]\n",
      "descriptors = \n",
      "{'layer': 'timeStep_4'}\n",
      "obs_descriptors = \n",
      "{'image': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])}\n",
      "channel_descriptors = \n",
      "{'channel': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
      "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
      "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
      "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
      "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
      "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
      "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
      "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
      "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
      "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
      "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
      "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
      "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
      "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
      "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
      "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
      "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
      "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
      "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
      "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
      "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
      "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
      "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
      "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
      "       871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
      "       884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
      "       897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
      "       910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n",
      "       923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
      "       936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n",
      "       949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
      "       962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n",
      "       975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n",
      "       988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])}\n",
      ", 'timeStep_5': rsatoolbox.data.Dataset(\n",
      "measurements = \n",
      "[[-1.2495415e+00  5.5326629e-01 -1.4409716e+00 ...  8.6419173e-02\n",
      "  -5.6540623e+00 -1.7320485e+00]\n",
      " [-1.6807367e+00  9.6192014e-01 -3.3767636e+00 ... -4.4678015e-01\n",
      "  -4.3711619e+00 -1.8812747e+00]\n",
      " [-5.0136232e-01  2.4600720e-01 -2.2192967e+00 ...  5.4476905e-01\n",
      "   2.9728365e-01  6.7677152e-01]\n",
      " ...\n",
      " [ 1.1293118e+00  1.7447338e+00  9.2226458e-01 ...  1.1561878e+00\n",
      "  -5.0595260e-01 -1.2936721e+00]\n",
      " [ 8.9817405e-01  9.2210555e-01 -9.3872571e-01 ...  1.0856310e+00\n",
      "   3.0405684e+00 -7.3691177e-01]\n",
      " [-3.4909308e-01  1.1078405e+00 -3.0082150e-04 ...  1.0121450e-01\n",
      "   3.0854309e-01  8.8181019e-01]]\n",
      "descriptors = \n",
      "{'layer': 'timeStep_5'}\n",
      "obs_descriptors = \n",
      "{'image': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])}\n",
      "channel_descriptors = \n",
      "{'channel': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
      "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
      "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
      "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
      "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
      "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
      "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
      "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
      "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
      "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
      "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
      "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
      "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
      "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
      "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
      "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
      "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
      "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
      "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
      "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
      "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
      "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
      "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
      "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
      "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
      "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
      "       611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
      "       624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636,\n",
      "       637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649,\n",
      "       650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662,\n",
      "       663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675,\n",
      "       676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688,\n",
      "       689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701,\n",
      "       702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714,\n",
      "       715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727,\n",
      "       728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740,\n",
      "       741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753,\n",
      "       754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766,\n",
      "       767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779,\n",
      "       780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792,\n",
      "       793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805,\n",
      "       806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818,\n",
      "       819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831,\n",
      "       832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844,\n",
      "       845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857,\n",
      "       858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870,\n",
      "       871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883,\n",
      "       884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896,\n",
      "       897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909,\n",
      "       910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922,\n",
      "       923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935,\n",
      "       936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948,\n",
      "       949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961,\n",
      "       962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974,\n",
      "       975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987,\n",
      "       988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# [timesteps, batchSize=128, paramCount=1000]\n",
    "'''\n",
    "dataset fields and their [correct] types: \n",
    "    measurements= measurements, type= numpy.ndarray\n",
    "    descriptors= {'layer': timeLayerName}, type= dict\n",
    "    obs_descriptors= {'image': np.arange(measurements.shape[0])}, type= dict\n",
    "    channel_descriptors= {'channel': np.arange(measurements.shape[1])}) type= dict\n",
    "'''\n",
    "\n",
    "snn_spk_datasets= {}\n",
    "for i, activations in enumerate(spk_stack_hid):\n",
    "    timeStep= i+1\n",
    "    timeLayerName= 'timeStep_'+str(timeStep)\n",
    "\n",
    "    #convert the torch tensor to numpy array to make it work with RSA, but first move it to cpu because its on the GPU\n",
    "    measurements= activations.cpu().numpy()\n",
    "    #shape @ each timeStep :  torch.Size([128, 1000]) = batchSize x layerSize\n",
    "\n",
    "    snn_spk_datasets[timeLayerName] = rsa.data.Dataset(measurements=measurements,\n",
    "                                            descriptors={'layer': timeLayerName},\n",
    "                                            obs_descriptors={'image': np.arange(measurements.shape[0])},\n",
    "                                            channel_descriptors={'channel': np.arange(measurements.shape[1])})\n",
    "print('\\n',snn_spk_datasets)\n",
    "\n",
    "\n",
    "\n",
    "snn_mem_datasets= {}\n",
    "for i, activations in enumerate(mem_stack_hid):\n",
    "    timeStep= i+1\n",
    "    timeLayerName= 'timeStep_'+str(timeStep)\n",
    "\n",
    "    #convert the torch tensor to numpy array to make it work with RSA, but first move it to cpu because its on the GPU\n",
    "    measurements= activations.cpu().numpy()\n",
    "    #shape @ each timeStep :  torch.Size([128, 1000]) = batchSize x layerSize\n",
    "\n",
    "    snn_mem_datasets[timeLayerName] = rsa.data.Dataset(measurements=measurements,\n",
    "                                            descriptors={'layer': timeLayerName},\n",
    "                                            obs_descriptors={'image': np.arange(measurements.shape[0])},\n",
    "                                            channel_descriptors={'channel': np.arange(measurements.shape[1])})\n",
    "print('\\n',snn_mem_datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fcfb0d",
   "metadata": {},
   "source": [
    "### RDMs of SNN Hidden Layer at each timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da0c2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "snn_spk_rdms_dict = {}\n",
    "for layer, dataset in snn_spk_datasets.items():\n",
    "    snn_spk_rdms_dict[layer] = rsa.rdm.calc_rdm(dataset)\n",
    "\n",
    "snn_spk_rdms= rsa.rdm.concat(snn_spk_rdms_dict.values())\n",
    "fig= rsa.vis.rdm_plot.show_rdm(snn_spk_rdms, rdm_descriptor= 'layer')[0]\n",
    "\n",
    "\n",
    "\n",
    "snn_mem_rdms_dict = {}\n",
    "for layer, dataset in snn_mem_datasets.items():\n",
    "    snn_mem_rdms_dict[layer] = rsa.rdm.calc_rdm(dataset)\n",
    "\n",
    "snn_mem_rdms= rsa.rdm.concat(snn_mem_rdms_dict.values())\n",
    "fig= rsa.vis.rdm_plot.show_rdm(snn_mem_rdms, rdm_descriptor= 'layer')[0]\n",
    "\n",
    "\n",
    "# same rdms different viz method:\n",
    "# show_rdm_plotly(snn_spk_rdms, rdm_descriptor= 'layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a642c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17ed2555",
   "metadata": {},
   "source": [
    "## Model Comparison and Statistical Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11b471e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'snn_spk_rdms_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msnn_spk_rdms_dict\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m timeStep \u001b[38;5;129;01min\u001b[39;00m snn_spk_rdms_dict\u001b[38;5;241m.\u001b[39mkeys():\u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'\u001b[39m, timeStep, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape: \u001b[39m\u001b[38;5;124m'\u001b[39m, snn_spk_rdms_dict[timeStep]\u001b[38;5;241m.\u001b[39mdissimilarities\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'snn_spk_rdms_dict' is not defined"
     ]
    }
   ],
   "source": [
    "print(snn_spk_rdms_dict.keys())\n",
    "for timeStep in snn_spk_rdms_dict.keys():print('    ', timeStep, 'shape: ', snn_spk_rdms_dict[timeStep].dissimilarities.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2cd8de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 32.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m fc1_rdm \u001b[38;5;241m=\u001b[39m snn_spk_rdms_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeStep_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfc1_rdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mviridis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDM  timeStep1 Layer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStimuli\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\richa\\OneDrive\\Dugree\\Project\\cuda\\lib\\site-packages\\seaborn\\matrix.py:446\u001b[0m, in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_HeatMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mannot_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m                      \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[0;32m    451\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidths\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m linewidths\n",
      "File \u001b[1;32mc:\\Users\\richa\\OneDrive\\Dugree\\Project\\cuda\\lib\\site-packages\\seaborn\\matrix.py:109\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    107\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 109\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(plot_data)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Validate the mask and convert to DataFrame\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array would exceed the maximum number of dimension of 32."
     ]
    }
   ],
   "source": [
    "# fc1_rdm = snn_spk_rdms_dict['timeStep_1']\n",
    "# plt.figure(figsize=(6,5))\n",
    "# sns.heatmap(fc1_rdm, cmap='viridis')\n",
    "# plt.title(\"RDM  timeStep1 Layer\")\n",
    "# plt.xlabel(\"Stimuli\")\n",
    "# plt.ylabel(\"Stimuli\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
